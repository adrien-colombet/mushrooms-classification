{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bbdf9df",
   "metadata": {},
   "source": [
    "# Tuning de InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a67154",
   "metadata": {},
   "source": [
    "L'objectif de ce notebook est de réaliser le tuning des hyperparamètres du modèle InceptionV3, réseau identifiés comme meilleur potentiel candidat pour la mise au point d'un modèle de classification du caractére comestible d'un champignon a partir d'une image.\n",
    "Les inputs de ce notebook sont :\n",
    "- le dataset d'images nettoyé et le fichier .csv correspondant au dataset d'images qui sera utilisé pour les parties train et test,\n",
    "- le dataset de validation avec le fichier .csv associé.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487bdbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "\n",
    "import  keras\n",
    "import tensorflow as tf # Utilisation de tensorflow v2.9.1\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61b7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des liens vers les dossiers et fichiers source\n",
    "images_dataset = r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\FFD_images_dataset'\n",
    "train_dataset = r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\train_FFDataframe_full_undersampling.csv'\n",
    "test_dataset = r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\test_FFDataframe_full_undersampling.csv'\n",
    "validation_dataset = r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\val_FFDataframe_full.csv'\n",
    "\n",
    "# dossier ou sauver les résultats obtenus sur les modèles\n",
    "save_models_results = r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Models_results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création de quelques fonctions utiles\n",
    "\n",
    "# affichage des metriques (accuracy, loss) d'entrainement d'un modèle\n",
    "def plot_scores(model, title):\n",
    "    '''\n",
    "    Arg :\n",
    "    model : model dont on souhaite afficher les metriques\n",
    "    Return:\n",
    "    plot des métriques Accuracy et loss sur les datasets train et test\n",
    "    '''\n",
    "    sns.set()\n",
    "    plt.rcParams['figure.figsize'] = [14,4]\n",
    "\n",
    "    # Créer la figure\n",
    "    fig = plt.figure()\n",
    "    \n",
    "    plt.gcf().subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0.3, hspace = 0.3)\n",
    "    # Créer les 4 graphiques\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    # Tracer les données sur les graphiques\n",
    "    ax1.plot(model.history['accuracy'], label = \"train\")\n",
    "    ax1.plot(model.history['val_accuracy'], label = \"test\")\n",
    "    ax1.legend(loc = \"lower right\")\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')    \n",
    "\n",
    "    ax2.plot(model.history['loss'], label = \"train\")\n",
    "    ax2.plot(model.history['val_loss'], label = \"test\")\n",
    "    ax2.legend(loc = \"upper right\")\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')  \n",
    "    plt.title(title, loc = \"left\")\n",
    "    plt.show()\n",
    "    \n",
    "# affichage de la matrice de confusion du dataset de validation\n",
    "def show_confusion_matrix(model):\n",
    "    '''\n",
    "    Args :\n",
    "    model : modele à utiliser pour fair eles predictions\n",
    "   \n",
    "    Return :\n",
    "    plot de la matrice de confusion\n",
    "    '''\n",
    "    # réalisation des prédiction pour le modèle\n",
    "    model_pred=model.predict(val_generator, steps=val_steps, verbose=1)\n",
    "    y_pred = []\n",
    "    for element in model_pred:\n",
    "        pred = np.argmax(element)\n",
    "        y_pred.append(pred)\n",
    "    y_val = df_val.edible.to_list()\n",
    "    confusion_mtx = confusion_matrix(y_val, y_pred)\n",
    "    #\n",
    "    plt.rcParams['font.size'] = 20\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusion_mtx)\n",
    "    disp.plot(cmap='Blues', values_format='d', xticks_rotation='horizontal', colorbar = False)\n",
    "    plt.title(f'Confusion matrix for {model}')\n",
    "    plt.ylabel('True label', fontsize = 20)\n",
    "    plt.yticks(fontsize = 20)\n",
    "    plt.xlabel('Predicted label', fontsize = 20)\n",
    "    plt.xticks(fontsize = 20)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "# création d'une fonction permettant de compiler un modèle\n",
    "def compile_model(model, optimizer, loss, metrics):\n",
    "    '''\n",
    "    Args :\n",
    "    model : model à compiler\n",
    "    optimizer :  choix de l'optimizer à utiliser durant l'entrainement\n",
    "    loss : fonction de loss à utiliser durant l'entrainement sous la forme : \"loss\"\n",
    "    metrics : metrique à évaluer durant l'entrainement sou sla forme : [\"metrics\"]\n",
    "    '''\n",
    "    model.compile(optimizer = optimizer, loss = loss, metrics = metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b34f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chargement des dataframes\n",
    "df_train = pd.read_csv(train_dataset)\n",
    "df_test = pd.read_csv(test_dataset)\n",
    "df_val = pd.read_csv(validation_dataset)\n",
    "\n",
    "# affichage de quelques infos sur ces dataframes + affichage d'une figure de répartition des catégories\n",
    "display(df_train.head(), df_test.info(), df_val.info())\n",
    "\n",
    "# génération des données du graph\n",
    "inedible = []\n",
    "edible = []\n",
    "\n",
    "dataframes = [df_train, df_test, df_val]\n",
    "for dataframe in dataframes:\n",
    "    count_inedible = dataframe['edible'].value_counts()[0]\n",
    "    inedible.append(count_inedible)\n",
    "    count_edible = dataframe['edible'].value_counts()[1]\n",
    "    edible.append(count_edible)   \n",
    "\n",
    "data = ['df_train', 'df_test', 'df_val']\n",
    "edibility = {'inedible': inedible, 'edible' : edible}\n",
    "\n",
    "colonnes = ['df_train', 'df_test', 'df_val']\n",
    "sex_counts = {\n",
    "    'inedible': inedible,\n",
    "    'edible': edible\n",
    "}\n",
    "\n",
    "width = 0.6\n",
    "fig, ax = plt.subplots()\n",
    "bottom = np.zeros(3)\n",
    "for i, j in edibility.items():\n",
    "    p = ax.bar(data, j, width, label=i, bottom=bottom)\n",
    "    bottom += j\n",
    "    ax.bar_label(p, label_type='center')\n",
    "ax.set_title('Number of images by category')\n",
    "ax.legend(title = 'categories')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03a0c6",
   "metadata": {},
   "source": [
    "## Création des modèle à tuner "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1741328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création par transfert learning d'un modèle de type ResNet50V2 à deux sorties\n",
    "TL_InceptionV3 = InceptionV3(include_top=False, pooling=\"avg\", weights='imagenet')\n",
    "for layer in TL_InceptionV3.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "logits = Dense(2)(TL_InceptionV3.layers[-1].output)\n",
    "output = Activation('softmax')(logits)\n",
    "TL_InceptionV3 = Model(TL_InceptionV3.input, output, name = 'TL_InceptionV3')\n",
    "TL_InceptionV3.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c131a3b",
   "metadata": {},
   "source": [
    "## Tuning de InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524be021",
   "metadata": {},
   "source": [
    "### Learning_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0127f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de quelques paramètres\n",
    "batch_size = 64\n",
    "SEED = 3\n",
    "epochs = 15\n",
    "W, H = 224, 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b16a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un DataGenerator pour le dataset d'entrainement\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_train[\"edible\"] = df_train[\"edible\"].apply(str)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train, images_dataset,\n",
    "                                                    x_col=\"filename\",\n",
    "                                                    y_col=\"edible\",\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=SEED)\n",
    "\n",
    "# Création d'un DataGenerator pour le dataset de test\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_test[\"edible\"] = df_test[\"edible\"].apply(str)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(df_test, images_dataset,\n",
    "                                                  x_col=\"filename\",\n",
    "                                                  y_col=\"edible\",\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe95315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres à compiler pour l'entrainement\n",
    "optimizer01 = optimizers.SGD(learning_rate = 0.1)\n",
    "optimizer001 = optimizers.SGD(learning_rate = 0.01)\n",
    "optimizer0001 = optimizers.SGD(learning_rate = 0.001)\n",
    "optimizer00001 = optimizers.SGD(learning_rate = 0.00001)\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207056d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation du modèle learning_rate = 0.1\n",
    "compile_model(TL_InceptionV3, optimizer01, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr01_bs64_SG_catcross.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr01_bs64_SG_catcross.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr01_bs64_SG_catcross = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9411f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation du modèle learning_rate = 0.01\n",
    "compile_model(TL_InceptionV3, optimizer001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr001_bs64_SG_catcross.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr001_bs64_SG_catcross.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr001_bs64_SG_catcross = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation du modèle learning_rate = 0.001\n",
    "compile_model(TL_InceptionV3, optimizer0001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr0001_bs64_SG_catcross.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr0001_bs64_SG_catcross.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr0001_bs64_SG_catcross = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compilation du modèle learning_rate = 0.0001\n",
    "compile_model(TL_InceptionV3, optimizer00001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr00001_bs64_SG_catcross.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr00001_bs64_SG_catcross.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr00001_bs64_SG_catcross = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage d'une synthèse du tuning du learning rate\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [14,4]\n",
    "\n",
    "    # Créer la figure\n",
    "fig = plt.figure()\n",
    "    \n",
    "plt.gcf().subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0.3, hspace = 0.3)\n",
    "    # Créer les 4 graphiques\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    # Tracer les données sur les graphiques\n",
    "ax1.plot(history_InceptionV3_lr01_bs64_SG_catcross.history['val_accuracy'], label = \"lr = 0.1\")\n",
    "ax1.plot(history_InceptionV3_lr001_bs64_SG_catcross.history['val_accuracy'], label = \"lr = 0.01\")\n",
    "ax1.plot(history_InceptionV3_lr0001_bs64_SG_catcross.history['val_accuracy'], label = \"lr = 0.001\")\n",
    "ax1.plot(history_InceptionV3_lr00001_bs64_SG_catcross.history['val_accuracy'], label = \"lr = 0.0001\")\n",
    "\n",
    "ax1.legend(loc = \"lower right\")\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('val_accuracy')    \n",
    "\n",
    "\n",
    "ax2.plot(history_InceptionV3_lr01_bs64_SG_catcross.history['val_loss'], label = \"lr = 0.1\")\n",
    "ax2.plot(history_InceptionV3_lr001_bs64_SG_catcross.history['val_loss'], label = \"lr = 0.01\")\n",
    "ax2.plot(history_InceptionV3_lr0001_bs64_SG_catcross.history['val_loss'], label = \"lr = 0.001\")\n",
    "ax2.plot(history_InceptionV3_lr00001_bs64_SG_catcross.history['val_loss'], label = \"lr = 0.0001\")\n",
    "ax2.legend(loc = \"upper right\")\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('val_loss')  \n",
    "plt.title(\"résultats du tuning du learning rate sur InceptionV3\", loc = \"left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b10e1",
   "metadata": {},
   "source": [
    "### Batch_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3755ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition de quelques paramètres\n",
    "SEED = 3\n",
    "epochs = 15\n",
    "W, H = 224, 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# Création d'un DataGenerator pour le dataset d'entrainement\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_train[\"edible\"] = df_train[\"edible\"].apply(str)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train, images_dataset,\n",
    "                                                    x_col=\"filename\",\n",
    "                                                    y_col=\"edible\",\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=SEED)\n",
    "\n",
    "# Création d'un DataGenerator pour le dataset de test\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_test[\"edible\"] = df_test[\"edible\"].apply(str)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(df_test, images_dataset,\n",
    "                                                  x_col=\"filename\",\n",
    "                                                  y_col=\"edible\",\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  batch_size=batch_size)\n",
    "# Choix des paramètres à compiler pour l'entrainement\n",
    "optimizer0001 = optimizers.SGD(learning_rate = 0.001)\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# compilation du modèle learning_rate = 0.001 et batch_size = 16\n",
    "compile_model(TL_InceptionV3, optimizer0001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr0001_bs16_SG_catcross.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr0001_bs16_SG_catcross.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr0001_bs16_SG_catcross = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbae7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "# Création d'un DataGenerator pour le dataset d'entrainement\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_train[\"edible\"] = df_train[\"edible\"].apply(str)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train, images_dataset,\n",
    "                                                    x_col=\"filename\",\n",
    "                                                    y_col=\"edible\",\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=SEED)\n",
    "\n",
    "# Création d'un DataGenerator pour le dataset de test\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_test[\"edible\"] = df_test[\"edible\"].apply(str)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(df_test, images_dataset,\n",
    "                                                  x_col=\"filename\",\n",
    "                                                  y_col=\"edible\",\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  batch_size=batch_size)\n",
    "# Choix des paramètres à compiler pour l'entrainement\n",
    "optimizer0001 = optimizers.SGD(learning_rate = 0.001)\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# compilation du modèle learning_rate = 0.001 et batch_size = 32\n",
    "compile_model(TL_InceptionV3, optimizer0001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr0001_bs32_SG_catcross.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr0001_bs32_SG_catcross.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr0001_bs32_SG_catcross = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a78688",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# Création d'un DataGenerator pour le dataset d'entrainement\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_train[\"edible\"] = df_train[\"edible\"].apply(str)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train, images_dataset,\n",
    "                                                    x_col=\"filename\",\n",
    "                                                    y_col=\"edible\",\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=SEED)\n",
    "\n",
    "# Création d'un DataGenerator pour le dataset de test\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_test[\"edible\"] = df_test[\"edible\"].apply(str)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(df_test, images_dataset,\n",
    "                                                  x_col=\"filename\",\n",
    "                                                  y_col=\"edible\",\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  batch_size=batch_size)\n",
    "# Choix des paramètres à compiler pour l'entrainement\n",
    "optimizer0001 = optimizers.SGD(learning_rate = 0.001)\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# compilation du modèle learning_rate = 0.001 et batch_size = 128\n",
    "compile_model(TL_InceptionV3, optimizer0001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr0001_bs128_SG_catcross.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr0001_bs128_SG_catcross.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr0001_bs128_SG_catcross = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c95ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage d'une synthèse du tuning du batch size\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [14,4]\n",
    "\n",
    "    # Créer la figure\n",
    "fig = plt.figure()\n",
    "    \n",
    "plt.gcf().subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0.3, hspace = 0.3)\n",
    "    # Créer les 4 graphiques\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    # Tracer les données sur les graphiques\n",
    "ax1.plot(history_InceptionV3_lr0001_bs16_SG_catcross.history['val_accuracy'], label = \"batch_size = 16\")\n",
    "ax1.plot(history_InceptionV3_lr0001_bs32_SG_catcross.history['val_accuracy'], label = \"batch_size = 32\")\n",
    "ax1.plot(history_InceptionV3_lr0001_bs64_SG_catcross.history['val_accuracy'], label = \"batch_size = 64\")\n",
    "ax1.plot(history_InceptionV3_lr0001_bs128_SG_catcross.history['val_accuracy'], label = \"batch_size = 128\")\n",
    "\n",
    "ax1.legend(loc = \"lower right\")\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('val_accuracy')    \n",
    "\n",
    "\n",
    "ax2.plot(history_InceptionV3_lr0001_bs16_SG_catcross.history['val_loss'], label = \"batch_size = 16\")\n",
    "ax2.plot(history_InceptionV3_lr0001_bs32_SG_catcross.history['val_loss'], label = \"batch_size = 32\")\n",
    "ax2.plot(history_InceptionV3_lr0001_bs64_SG_catcross.history['val_loss'], label = \"batch_size = 64\")\n",
    "ax2.plot(history_InceptionV3_lr0001_bs128_SG_catcross.history['val_loss'], label = \"batch_size = 128\")\n",
    "ax2.legend(loc = \"upper right\")\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('val_loss')  \n",
    "plt.title(\"résultats du tuning du learning rate sur InceptionV3\", loc = \"left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118db972",
   "metadata": {},
   "source": [
    "###  Loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aad604",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# Création d'un DataGenerator pour le dataset d'entrainement\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_train[\"edible\"] = df_train[\"edible\"].apply(str)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(df_train, images_dataset,\n",
    "                                                    x_col=\"filename\",\n",
    "                                                    y_col=\"edible\",\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=SEED)\n",
    "\n",
    "# Création d'un DataGenerator pour le dataset de test\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "df_test[\"edible\"] = df_test[\"edible\"].apply(str)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(df_test, images_dataset,\n",
    "                                                  x_col=\"filename\",\n",
    "                                                  y_col=\"edible\",\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  batch_size=batch_size)\n",
    "# Choix des paramètres à compiler pour l'entrainement\n",
    "optimizer0001 = optimizers.SGD(learning_rate = 0.001)\n",
    "loss = \"hinge\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# compilation du modèle learning_rate = 0.001 et batch_size = 32\n",
    "compile_model(TL_InceptionV3, optimizer0001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr0001_bs128_SG_hinge.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr0001_bs128_SG_hinge.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr0001_bs128_SG_hinge = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcf53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage d'une synthèse du tuning de la loss_function\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [14,4]\n",
    "\n",
    "    # Créer la figure\n",
    "fig = plt.figure()\n",
    "    \n",
    "plt.gcf().subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0.3, hspace = 0.3)\n",
    "    # Créer les 4 graphiques\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    # Tracer les données sur les graphiques\n",
    "\n",
    "ax1.plot(history_InceptionV3_lr0001_bs128_SG_catcross.history['val_accuracy'], label = \"loss_function = categorical_crossentropy\")\n",
    "ax1.plot(history_InceptionV3_lr0001_bs128_SG_hinge.history['val_accuracy'], label = \"loss_function = hinge\")\n",
    "ax1.legend(loc = \"right\")\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('val_accuracy')    \n",
    "\n",
    "ax2.plot(history_InceptionV3_lr0001_bs128_SG_catcross.history['val_loss'], label = \"loss_function = categorical_crossentropy\")\n",
    "ax2.plot(history_InceptionV3_lr0001_bs128_SG_hinge.history['val_loss'], label = \"loss_function = hinge\")\n",
    "ax2.legend(loc = \"right\")\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('val_loss')  \n",
    "plt.title(\"résultats du tuning de la loss_function sur InceptionV3\", loc = \"left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10881bcf",
   "metadata": {},
   "source": [
    "### Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0abae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres à compiler pour l'entrainement\n",
    "optimizer0001 = optimizers.Adam(learning_rate = 0.001)\n",
    "loss = \"hinge\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# compilation du modèle learning_rate = 0.001 et batch_size = 128\n",
    "compile_model(TL_InceptionV3, optimizer0001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr0001_bs128_Adam_hinge.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr0001_bs128_Adam_hinge.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr0001_bs128_Adam_hinge = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69586b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix des paramètres à compiler pour l'entrainement\n",
    "optimizer0001 = optimizers.RMSprop(learning_rate = 0.001)\n",
    "loss = \"hinge\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "# compilation du modèle learning_rate = 0.001 et batch_size = 32\n",
    "compile_model(TL_InceptionV3, optimizer0001, loss, metrics)\n",
    "\n",
    "# création de callbacks\n",
    "checkpointer_InceptionV3 = ModelCheckpoint(filepath=os.path.join(save_models_results, \"InceptionV3_lr0001_bs128_RMSprop_hinge.hdf5\"),\n",
    "                                            monitor='val_loss',\n",
    "                                            save_best_only=True,\n",
    "                                            mode='auto')\n",
    "CSV_logger_InceptionV3 = CSVLogger(filename = 'logger_InceptionV3_lr0001_bs128_RMSprop_hinge.csv',\n",
    "                                    separator=',',\n",
    "                                    append = True)\n",
    "callbacks_InceptionV3 = [checkpointer_InceptionV3, CSV_logger_InceptionV3]\n",
    "\n",
    "# entrainement du modèle\n",
    "start_time = time.time()\n",
    "history_InceptionV3_lr0001_bs128_RMSprop_hinge = TL_InceptionV3.fit_generator(train_generator,\n",
    "                                                    epochs=epochs,\n",
    "                                                    validation_data=test_generator,\n",
    "                                                    validation_steps=len(df_test)//batch_size,\n",
    "                                                    steps_per_epoch=len(df_train)//batch_size,\n",
    "                                                    callbacks=callbacks_InceptionV3)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Durée de l'entrainement :\", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc4261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage d'une synthèse du tuning de l'optimizer\n",
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [14,4]\n",
    "\n",
    "    # Créer la figure\n",
    "fig = plt.figure()\n",
    "    \n",
    "plt.gcf().subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0.3, hspace = 0.3)\n",
    "    # Créer les 4 graphiques\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "    # Tracer les données sur les graphiques\n",
    "\n",
    "\n",
    "ax1.plot(history_InceptionV3_lr0001_bs128_SG_hinge.history['val_accuracy'], label = \"optimizer = SGD\")\n",
    "ax1.plot(history_InceptionV3_lr0001_bs128_Adam_hinge.history['val_accuracy'], label = \"optimizer = Adam\")\n",
    "ax1.plot(history_InceptionV3_lr0001_bs128_RMSprop_hinge.history['val_accuracy'], label = \"optimizer = RMSprop\")\n",
    "ax1.legend(loc = \"lower right\")\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('val_accuracy')    \n",
    "\n",
    "ax2.plot(history_InceptionV3_lr0001_bs128_SG_hinge.history['val_loss'], label = \"optimizer = SGD\")\n",
    "ax2.plot(history_InceptionV3_lr0001_bs128_Adam_hinge.history['val_loss'], label = \"optimizer = Adam\")\n",
    "ax2.plot(history_InceptionV3_lr0001_bs128_RMSprop_hinge.history['val_loss'], label = \"optimizer = RMSprop\")\n",
    "ax2.legend(loc = \"upper right\")\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('val_loss')  \n",
    "plt.title(\"résultats du tuning de l'optimizer sur InceptionV3\", loc = \"left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b839e89",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Le tuning des hyperparamètres du modèle InceptionV3 permet d'effectuer les choix suivants pour l'entraienment du meilleur modèle dans le cas de la classification sur le caractère comestible de champignons  :\n",
    "- batch_size = 128\n",
    "- optimizer = RMSprop avec un learning_rate de 0.001\n",
    "- loss_function = \"hinge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eba7f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sauvegarde des résultats de tuning pour streamlit\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr01_bs64_SG_catcross.joblib')\n",
    "dump(history_InceptionV3_lr01_bs64_SG_catcross, path_save_name, 3)\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr001_bs64_SG_catcross.joblib')\n",
    "dump(history_InceptionV3_lr001_bs64_SG_catcross, path_save_name, 3)\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr0001_bs64_SG_catcross.joblib')\n",
    "dump(history_InceptionV3_lr0001_bs64_SG_catcross, path_save_name, 3)\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr00001_bs64_SG_catcross.joblib')\n",
    "dump(history_InceptionV3_lr00001_bs64_SG_catcross, path_save_name, 3)\n",
    "\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr0001_bs16_SG_catcross.joblib')\n",
    "dump(history_InceptionV3_lr0001_bs16_SG_catcross, path_save_name, 3)\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr0001_bs32_SG_catcross.joblib')\n",
    "dump(history_InceptionV3_lr0001_bs32_SG_catcross, path_save_name, 3)\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr0001_bs128_SG_catcross.joblib')\n",
    "dump(history_InceptionV3_lr0001_bs128_SG_catcross, path_save_name, 3)\n",
    "\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr0001_bs128_SG_hinge.joblib')\n",
    "dump(history_InceptionV3_lr0001_bs128_SG_hinge, path_save_name, 3)\n",
    "\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr0001_bs128_Adam_hinge.joblib')\n",
    "dump(history_InceptionV3_lr0001_bs128_Adam_hinge, path_save_name, 3)\n",
    "\n",
    "path_save_name = os.path.join(save_models_results, 'history_InceptionV3_lr0001_bs128_RMSprop_hinge.joblib')\n",
    "dump(history_InceptionV3_lr0001_bs128_RMSprop_hinge, path_save_name, 3)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
