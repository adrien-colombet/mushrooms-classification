{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96dde805",
   "metadata": {},
   "source": [
    "# Preprocessing pour Xception"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59c4e0bc",
   "metadata": {},
   "source": [
    "l'objectif de ce notebook est de réaliser les étapes de preprocessing necessaire pour entrainer un modele de classification binaire de champignon sur le critere comestible / non comestible.\n",
    "Ce notebook prend en input un dossier d'images classées en 2 catégories (edible / inedible) et retourne :\n",
    "- un dataframe réduit et équilibré des catégories (500 images par classe)\n",
    "- une arborescence :\n",
    "-dataset\n",
    "|----train\n",
    "     |----edible\n",
    "     |----inedible\n",
    "|----test\n",
    "     |----edible\n",
    "     |----inedible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f98bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition du repertoire de travail\n",
    "data_dir = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\reduced_dataset\\full\"\n",
    "\n",
    "# définition du nombre d'images par classe dans le dataset\n",
    "size_dataset = 500\n",
    "random = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd518b60",
   "metadata": {},
   "source": [
    "## Création du dataframe réduit équilibré"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7004a048",
   "metadata": {},
   "source": [
    "### Création d'un dataframe associé au dataset initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames_from_subfolder(subfolder_path):\n",
    "  # Obtenir une liste de noms de fichiers.\n",
    "    filenames = os.listdir(subfolder_path)\n",
    "  # Filtrer les dossiers.\n",
    "    filenames = [filename for filename in filenames if os.path.isfile(os.path.join(subfolder_path, filename))]\n",
    "    return filenames\n",
    "\n",
    "subfolder_path = f\"{data_dir}/edible\"\n",
    "filenames_edible = pd.Series(get_filenames_from_subfolder(subfolder_path))\n",
    "subfolder_path = f\"{data_dir}/inedible\"\n",
    "filenames_inedible = pd.Series(get_filenames_from_subfolder(subfolder_path))\n",
    "\n",
    "df_edible = pd.DataFrame(columns = ['filename', 'label'])\n",
    "df_inedible = pd.DataFrame(columns = ['filename', 'label'])\n",
    "df_edible.filename = filenames_edible\n",
    "df_inedible.filename = filenames_inedible\n",
    "df_edible[\"label\"] = df_edible[\"label\"].fillna('edible')\n",
    "df_inedible[\"label\"] = df_inedible[\"label\"].fillna('inedible')\n",
    "print(df_edible.label.value_counts())\n",
    "print(df_inedible.label.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb064cf6",
   "metadata": {},
   "source": [
    "### Création d'un dataframe sous-échantillonné et équilibré sur les classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ce2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_edible.sample(size_dataset, random_state=random), df_inedible.sample(size_dataset, random_state=random)], ignore_index=True)\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6229d145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création des partitions train et test\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state = random)\n",
    "\n",
    "# création de listes d'images edible et inedible pour les partitions train et test\n",
    "train_edible = df_train.filename[df_train.label == 'edible'].tolist()\n",
    "train_inedible = df_train.filename[df_train.label == 'inedible'].tolist()\n",
    "test_edible = df_test.filename[df_test.label == 'edible'].tolist()\n",
    "test_inedible = df_test.filename[df_test.label == 'inedible'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddd2900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des dataframes créés\n",
    "# pour le dataset complet non catégorisé\n",
    "df_train.to_csv(f\"{data_dir}/df_train.csv\", index = False)\n",
    "df_test.to_csv(f\"{data_dir}/df_test.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c7aaa3",
   "metadata": {},
   "source": [
    "## Création de l'arborecence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dossier principal\n",
    "os.mkdir(os.path.join(data_dir, 'reduced_dataset'))\n",
    "\n",
    "# Création des deux sous-dossiers train, test\n",
    "os.mkdir(os.path.join(data_dir, 'reduced_dataset', 'train'))\n",
    "os.mkdir(os.path.join(data_dir, 'reduced_dataset', 'test'))\n",
    "\n",
    "# Création des deux sous-dossiers edible et inedible dans train et test\n",
    "os.mkdir(os.path.join(data_dir, 'reduced_dataset', 'train', 'edible'))\n",
    "os.mkdir(os.path.join(data_dir, 'reduced_dataset', 'test', 'edible'))\n",
    "os.mkdir(os.path.join(data_dir, 'reduced_dataset', 'train', 'inedible'))\n",
    "os.mkdir(os.path.join(data_dir, 'reduced_dataset', 'test', 'inedible'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7cdc8c",
   "metadata": {},
   "source": [
    "### copie des images dans les différents dossiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38391eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copie des images pour la partie train edible\n",
    "# itération sur les noms d'images\n",
    "for image_name in train_edible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(f\"{data_dir}/edible\", image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(f\"{data_dir}/reduced_dataset/train/edible\", image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "\n",
    "# copie des images pour la partie train inedible\n",
    "# itération sur les noms d'images\n",
    "for image_name in train_inedible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(f\"{data_dir}/inedible\", image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(f\"{data_dir}/reduced_dataset/train/inedible\", image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "\n",
    "# copie des images pour la partie test edible\n",
    "# itération sur les noms d'images\n",
    "for image_name in test_edible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(f\"{data_dir}/edible\", image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(f\"{data_dir}/reduced_dataset/test/edible\", image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "\n",
    "# copie des images pour la partie test inedible\n",
    "# itération sur les noms d'images\n",
    "for image_name in test_inedible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(f\"{data_dir}/inedible\", image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(f\"{data_dir}/reduced_dataset/test/inedible\", image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
