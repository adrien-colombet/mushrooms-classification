{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2ee5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282735e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_datasets as tfds\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "#print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bf364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import du dataset\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "df = pd.read_csv('../dataset/edible_mushrooms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32995fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(18, 8))\n",
    "ax = sns.countplot(data = df, x = 'order', alpha = 0.7)\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "ax.set_xlabel('order')\n",
    "ax.set_ylabel('nombre de photos')\n",
    "ax.set_title('nombre de photos par species pour les champignons comestibles');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a27bc",
   "metadata": {},
   "source": [
    "# Balacing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee03bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sous Ã©chantillonnage de 'df_species_uncom'\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Create the RandomUnderSampler object\n",
    "undersample = RandomUnderSampler(sampling_strategy = 'auto')\n",
    "\n",
    "# Undersample the dataframe\n",
    "X = df.drop(columns = 'order')\n",
    "y = df['order']\n",
    "X_under, y_under = undersample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855ef536",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4be74f",
   "metadata": {},
   "source": [
    "# Generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f7dd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../dataset/class_order'\n",
    "train_path='../dataset/class_order/train'\n",
    "test_path='../dataset/class_order/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316b64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input,\n",
    "    shear_range = 0.2, # random application of shearing\n",
    "    zoom_range = 0.2,\n",
    "    rotation_range = 45,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07343b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_data_generator.flow_from_directory(\n",
    "    directory = train_path,\n",
    "    class_mode = \"sparse\",\n",
    "    target_size = (224,224), batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a34b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_generator = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5523a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = test_data_generator.flow_from_directory(\n",
    "    directory = test_path,\n",
    "    class_mode = \"sparse\",\n",
    "    target_size = (224,224), batch_size = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0141d9",
   "metadata": {},
   "source": [
    "## balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Get the true labels from the generator\n",
    "y_train = train_generator.classes\n",
    "\n",
    "# Compute the class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes = np.unique(y_train), y = y_train)\n",
    "\n",
    "# Create a dictionary mapping class indices to class weights\n",
    "class_weight_dict = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde0aa60",
   "metadata": {},
   "source": [
    "# VGG16 transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c1bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "n_class= df['order'].unique().shape[0]\n",
    "\n",
    "#base_model = MobileNet(weights = 'imagenet', include_top = False, input_shape=(224,224,3))\n",
    "base_model = VGG16(weights = 'imagenet', include_top = False)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D()) \n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e898aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "               loss='sparse_categorical_crossentropy', \n",
    "               metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256e627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Train the model on the preprocessed images and labels from the dataframe\n",
    "batch_size = 16\n",
    "\n",
    "#tf.debugging.disable_traceback_filtering()\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs = 5,\n",
    "    validation_data=test_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9691ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume `history` is the history object returned by the `fit` method\n",
    "# Plot the accuracy and validation accuracy\n",
    "plt.plot(model_history.history['acc'])\n",
    "plt.plot(model_history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f938b97",
   "metadata": {},
   "source": [
    "# transfer learning on Mobile Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "n_class= df['order'].unique().shape[0]\n",
    "\n",
    "base_model = MobileNet(weights = 'imagenet', include_top = False, input_shape=(224,224,3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_mobile = Sequential()\n",
    "model_mobile.add(base_model)\n",
    "model_mobile.add(GlobalAveragePooling2D()) \n",
    "model_mobile.add(Dense(1024,activation='relu'))\n",
    "model_mobile.add(Dropout(rate=0.1))\n",
    "model_mobile.add(Dense(n_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20ab8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobile.compile(optimizer='adam', \n",
    "               loss='sparse_categorical_crossentropy', \n",
    "               metrics=['acc'])\n",
    "model_mobile.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fae74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Create an early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='acc', patience=2, min_delta = 0.01)\n",
    "\n",
    "model_mobile_history = model_mobile.fit(\n",
    "    train_generator,\n",
    "    epochs = 1,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c01ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume `history` is the history object returned by the `fit` method\n",
    "# Plot the accuracy and validation accuracy\n",
    "plt.plot(model_mobile_history.history['acc'])\n",
    "plt.plot(model_mobile_history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c445179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume `history` is the history object returned by the `fit` method\n",
    "# Plot the accuracy and validation accuracy\n",
    "plt.plot(model_mobile_history.history['acc'])\n",
    "plt.plot(model_mobile_history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fe5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_proba = model_mobile.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "y_true = test_generator.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea58ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can observe the tendency to classify any mushroom as part of the dominant class, a consequence of imbalancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4188def8",
   "metadata": {},
   "source": [
    "## Individual image analysis for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e2854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "base_model = models.mobilenet_v2(pretrained=True)\n",
    "for param in base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model_mobile = nn.Sequential(\n",
    "    base_model,\n",
    "    nn.AdaptiveAvgPool2d((1, 1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(1280, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.1),\n",
    "    nn.Linear(1024, n_class),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_mobile.parameters())\n",
    "\n",
    "print(model_mobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f32a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7558add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n",
    "    deprocess_image, \\\n",
    "    preprocess_image\n",
    "from torchvision.models import resnet50\n",
    "from requests import get\n",
    "import cv2\n",
    "\n",
    "#model = resnet50(pretrained=True)\n",
    "model = model_mobile\n",
    "\n",
    "image_url = \"https://th.bing.com/th/id/R.94b33a074b9ceeb27b1c7fba0f66db74?rik=wN27mvigyFlXGg&riu=http%3a%2f%2fimages5.fanpop.com%2fimage%2fphotos%2f31400000%2fBear-Wallpaper-bears-31446777-1600-1200.jpg&ehk=oD0JPpRVTZZ6yizZtGQtnsBGK2pAap2xv3sU3A4bIMc%3d&risl=&pid=ImgRaw&r=0\"\n",
    "img_stream = get(image_url, stream=True).raw\n",
    "img = np.array(Image.open(img_stream))\n",
    "img = cv2.resize(img, (224, 224))\n",
    "img = np.float32(img) / 255\n",
    "input_tensor = preprocess_image(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# Note: input_tensor can be a batch tensor with several images!\n",
    "\n",
    "\n",
    "# The target for the CAM is the Bear category.\n",
    "# As usual for classication, the target is the logit output\n",
    "# before softmax, for that category.\n",
    "targets = [ClassifierOutputTarget(295)]\n",
    "#target_layers = [model.layer4]\n",
    "target_layers = [model.layer4]\n",
    "\n",
    "with GradCAM(model=model, target_layers=target_layers) as cam:\n",
    "    grayscale_cams = cam(input_tensor=input_tensor, targets=targets)\n",
    "    cam_image = show_cam_on_image(img, grayscale_cams[0, :], use_rgb=True)\n",
    "cam = np.uint8(255*grayscale_cams[0, :])\n",
    "cam = cv2.merge([cam, cam, cam])\n",
    "images = np.hstack((np.uint8(255*img), cam , cam_image))\n",
    "Image.fromarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e49344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87d41c96",
   "metadata": {},
   "source": [
    "## on the balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e243cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Create an early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "# Fit the model using the class weights\n",
    "model_mobile_balanced_history = model_mobile.fit_generator(\n",
    "    train_generator,\n",
    "    class_weight=class_weight_dict,\n",
    "    epochs = 10,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca80349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume `history` is the history object returned by the `fit` method\n",
    "# Plot the accuracy and validation accuracy\n",
    "plt.plot(model_mobile_balanced_history.history['acc'])\n",
    "plt.plot(model_mobile_balanced_history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef5c06",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred_proba = model_mobile.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "y_true = test_generator.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Display the confusion matrix\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b458ab",
   "metadata": {},
   "source": [
    "# Background removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23f7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "\n",
    "# Read the image into a NumPy array\n",
    "image = imageio.v3.imread('../dataset/images/0/18.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import SamAutomaticMaskGenerator, sam_model_registry\n",
    "sam = sam_model_registry[\"default\"](checkpoint=\"../sam_vit_h_4b8939.pth\")\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "masks = mask_generator.generate(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import supervision as sv\n",
    "\n",
    "mask_annotator = sv.MaskAnnotator()\n",
    "detections = sv.Detections.from_sam(masks)\n",
    "annotated_image = mask_annotator.annotate(image, detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbb6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(annotated_image)\n",
    "\n",
    "\n",
    "# Remove the axis\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "\n",
    "\n",
    "# Remove the axis\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b142e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# derive background mask\n",
    "background_mask = np.logical_not(np.logical_or.reduce(detections.mask))\n",
    "\n",
    "# Apply the mask to the image\n",
    "masked_image = np.where(background_mask[..., None], 0, image)\n",
    "\n",
    "# Display image af\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(masked_image)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc12457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
