{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7c5e667",
   "metadata": {},
   "source": [
    "# Exploration du jeu d'images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3331479",
   "metadata": {},
   "source": [
    "L'objectif de ce notebook est d'explorer le jeu d'images du usecase et d'identifier les différents biais. A l'issue de ce notebook, le dataset d'image aura été nettoyé.\n",
    "les inputs de ce notebook sont :\n",
    "- le jeu d'images obtenu suite à de l'etape de nettoyage des données .csv\n",
    "- le fichier .csv correspondant au jeu d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d8aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image, ImageStat\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b61033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# définition du dossier image source du usecase\n",
    "full_images = r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\dataset_cleaned'\n",
    "\n",
    "# définition du chemin d'accés du dataframe contenant les infos de l'étude\n",
    "dataframe_dataset = r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\cleaned_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dded77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataframe_dataset)\n",
    "df_filtered = df['filename'].sample(frac = 1/50)\n",
    "test_resolution = df_filtered.tolist()\n",
    "print(len(test_resolution))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc17e3d",
   "metadata": {},
   "source": [
    "## Quelques informations générales sur le jeu de données d'images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e640554a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des informations sur la taille des images\n",
    "sizes = []\n",
    "for file in os.listdir(full_images):\n",
    "    if os.path.isfile(os.path.join(full_images, file)) and file.endswith(\".jpg\"):\n",
    "        sizes.append(os.path.getsize(os.path.join(full_images, file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération des informations sur le contrast et la luminosité des images\n",
    "def get_image_contrast_brightness(image_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)                         # Convert the image to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)     # Calculate the standard deviation of the pixel intensities\n",
    "    contrast = np.std(img_gray)                          # Calculate the average pixel brightness\n",
    "    brightness = np.mean(img_gray)    \n",
    "    return contrast, brightness\n",
    "\n",
    "contrast_list = []\n",
    "brightness_list = []\n",
    "for file in os.listdir(full_images):\n",
    "    if os.path.isfile(os.path.join(full_images, file)) and file.endswith(\".jpg\"):\n",
    "        file_path = os.path.join(full_images, file)\n",
    "        contrast,brightness = get_image_contrast_brightness(file_path)\n",
    "        contrast_list.append(contrast)\n",
    "        brightness_list.append(brightness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identification du format de couleur des images\n",
    "def is_grayscale(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    w, h = img.size\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            r, g, b = img.getpixel((i,j))\n",
    "            if r != g != b:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "greyscale_list = []\n",
    "rgb_list = []\n",
    "for file in os.listdir(full_images):\n",
    "    if os.path.isfile(os.path.join(full_images, file)) and file.endswith(\".jpg\"):\n",
    "            if (is_grayscale(os.path.join(full_images, file))):\n",
    "                greyscale_list.append(file)\n",
    "            else:\n",
    "                rgb_list.append(file)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3164a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sizes), len(contrast_list), len(brightness_list), len(greyscale_list), len(rgb_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ea0e9",
   "metadata": {},
   "source": [
    "#### création d'une figure résumant ces informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [8, 8]\n",
    "\n",
    "# Créer la figure\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.gcf().subplots_adjust(left = 0, bottom = 0, right = 1, top = 1, wspace = 0.3, hspace = 0.3)\n",
    "# Créer les 4 graphiques\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "\n",
    "# Tracer les données sur les graphiques\n",
    "ax1.hist(x = sizes, bins = 100, density = True)\n",
    "ax2.bar(list_labels, list_sizes)\n",
    "ax3.hist(x = contrast_list, bins = 100, density = True)\n",
    "ax4.hist(x = brightness_list, bins = 100, density = True)\n",
    "\n",
    "ax1.set_xlabel('Taille des fichiers en octets')\n",
    "ax1.set_ylabel('Densité de fichiers')\n",
    "ax2.set_xlabel('Nuance de couleur')\n",
    "ax2.set_ylabel('Nombre de fichiers')\n",
    "ax2.set_yscale('log')\n",
    "ax3.set_ylabel('Densité')\n",
    "ax3.set_xlabel('distribution du contraste')\n",
    "ax4.set_ylabel('Densité')\n",
    "ax4.set_xlabel('distribution de la luminosité')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b7cf6",
   "metadata": {},
   "source": [
    "Les images en nuance de gris pourront etre supprimées car leur proportion est trés faible dans le dataset.\n",
    "Les images sont de petites dimensions, la distribution du contraste et de la luminosité sont de type gaussien."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c919bc",
   "metadata": {},
   "source": [
    "## Identification des images sur fond blanc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd61e2",
   "metadata": {},
   "source": [
    "L'objectif est ici de créer une liste des images sur fond blanc (images qui ne sont probablement pas des photos réelles) et qui risquent de fausser l'entrainement d'un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b084b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une fonction permettant d'identifier les images ayant les pixels des angles blancs\n",
    "def has_white_background(image: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    Retourne True si les coin de l'imaage sont blancs, False sinon\n",
    "    image: image as a NumPy array.\n",
    "     \"\"\"\n",
    "    # récupération des dimensions de l'image\n",
    "    height, width = image.shape\n",
    "\n",
    "    # Contrôle des valeurs des pixels des angles\n",
    "    if (np.all(image[0, 0] == 255) and\n",
    "        np.all(image[0, width-1] == 255) and\n",
    "        np.all(image[height-1, 0] == 255) and\n",
    "        np.all(image[height-1, width-1] == 255)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# création d'une liste d'images à fond blanc\n",
    "white_background = []\n",
    "for subdir, _, files in os.walk(full_images):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            with Image.open(os.path.join(subdir, file)) as img:\n",
    "                if has_white_background(np.array(img.convert('L'))):\n",
    "                    white_background.append(file)\n",
    "print(len(white_background))\n",
    "\n",
    "# création de fonctions permettant de générer une grille de 100 images avec des transformations (rotation) aléatoires\n",
    "def get_side(img, side_type, n = 5):\n",
    "    h, w, c = img.shape\n",
    "    if side_type == \"horizontal\":\n",
    "        return np.ones((h,n,c))\n",
    "    return np.ones((n,w,c))\n",
    "\n",
    "def show_gallery(im_ls,n=5, shuffle=True):\n",
    "    images = []\n",
    "    vertical_images = []\n",
    "    if shuffle:\n",
    "        random.shuffle(im_ls)\n",
    "    vertical_images = []\n",
    "    for i in range(n*n):\n",
    "        img = load_img(os.path.join(IMAGE_DIR,im_ls[i]), target_size=(W,H))\n",
    "        img = img_to_array(img)\n",
    "        hside = get_side(img,side_type=\"horizontal\")\n",
    "        images.append(img)\n",
    "        images.append(hside)\n",
    "        \n",
    "        if (i+1) % n == 0:\n",
    "            himage=np.hstack((images))\n",
    "            vside = get_side(himage, side_type=\"vertical\")\n",
    "            vertical_images.append(himage)\n",
    "            vertical_images.append(vside)\n",
    "            \n",
    "            images = []\n",
    "        \n",
    "    gallery = np.vstack((vertical_images))\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gallery.astype(np.uint8))\n",
    "    plt.show()\n",
    "    \n",
    "# observation d'une grille d'images sur fond blanc\n",
    "IMAGE_DIR = full_images\n",
    "W, H = 224, 224\n",
    "show_gallery(white_background, n=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446f516c",
   "metadata": {},
   "source": [
    "Les images de la liste 'white_background' pourront être supprimées car ce sont essentiellement des dessins et schémas qui risquent de fausser l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3707690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une liste d'images à supprimer\n",
    "images_to_delete = white_background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a894cf6",
   "metadata": {},
   "source": [
    "## Identifcation des images sur fond noir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbd805d",
   "metadata": {},
   "source": [
    "L'objectif est ici de créer une liste des images prises au microscope (fond noir + cercle de prise de vue) afin de pouvoir les écarter du jeu de données qui servira pour les entrainements de modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50947585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une fonction permettant d'identifier les images ayant les pixels des angles noirs\n",
    "def has_black_background(image: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    Retourne True si le fond de l'image est noir, False sinon.\n",
    "    image: image as a NumPy array.\n",
    "    \"\"\"\n",
    "    # Recupération des dimensions de l'image\n",
    "    height, width = image.shape\n",
    "\n",
    "    # Contrôle des valeurs des pixels de angles\n",
    "    if (np.all(image[0, 0] == 0) and\n",
    "        np.all(image[0, width-1] == 0) and\n",
    "        np.all(image[height-1, 0] == 0) and\n",
    "        np.all(image[height-1, width-1] == 0)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# création d'une liste des images ayant les pixels des angles moirs\n",
    "black_background_images = []\n",
    "for subdir, _, files in os.walk(full_images):\n",
    "    for file in files:\n",
    "        if file.endswith('.jpg'):\n",
    "            with Image.open(os.path.join(subdir, file)) as img:\n",
    "                if has_black_background(np.array(img.convert('L'))):\n",
    "                    black_background_images.append(file)\n",
    "print(len(black_background_images))\n",
    "\n",
    "# affichage d'une grille d'images ayant un fond noir\n",
    "show_gallery(black_background_images, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d56a1f",
   "metadata": {},
   "source": [
    "Les images de la liste 'black_background_images' pourront être supprimées car ce sont essentiellement d'images prises au microscope qui risquent de fausser l'apprentissage et la perte d'images non aquises au microscope reste trés faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e4d874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mise à jour de la liste d'images à supprimer\n",
    "for filename in black_background_images:\n",
    "    images_to_delete.append(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe503fd",
   "metadata": {},
   "source": [
    "## Recherche de nettoyage des données sur le format des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e5b2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'un dataframe avec les résolutions des images\n",
    "resolutions = []\n",
    "\n",
    "for file in os.listdir(full_images):\n",
    "    image = PIL.Image.open(os.path.join(full_images, file))\n",
    "    W, H = image.width, image.height\n",
    "    resolution = [W, H]\n",
    "    resolutions.append(resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39629f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tri des résolutions\n",
    "def tri_resolutions(liste):\n",
    "    '''\n",
    "  Trie une liste de couples de chiffres en ordonnant pour chaque couple de chiffre la plus grande des deux valeurs en premier.\n",
    "  Args:\n",
    "    liste: La liste des résolutions à trier.\n",
    "  Returns:\n",
    "    La liste des résolutions triées.\n",
    "'''\n",
    "    for resolution in liste:\n",
    "        if resolution[0] < resolution[1]:\n",
    "            resolution[0], resolution[1] = resolution[1], resolution[0]\n",
    "    return resolutions\n",
    "\n",
    "tri_resolutions(resolutions)\n",
    "\n",
    "# création d'un dataframe avec les résolutions des images\n",
    "width = []\n",
    "height = []\n",
    "for resolution in resolutions:\n",
    "    width.append(resolution[0])\n",
    "    height.append(resolution[1])\n",
    "\n",
    "files = os.listdir(full_images)\n",
    "\n",
    "# construction du dataframe\n",
    "data = {'filename' : pd.Series(files), 'width' : pd.Series(width), 'height' : pd.Series(height)}\n",
    "df_resolutions = pd.DataFrame(data = data)\n",
    "# ajout d'une colonne concatenant largeur et hauteur pour chaque image\n",
    "df_resolutions['image_size'] = df_resolutions['width'].astype(str) + 'x' + df_resolutions['height'].astype(str)\n",
    "# sauvegarde du dataframe\n",
    "dossier_parent = os.path.dirname(full_images)\n",
    "os.chdir(dossier_parent)\n",
    "df_resolutions.to_csv(f\"{os.getcwd()}/df_resolutions.csv\")\n",
    "\n",
    "\n",
    "# création d'un barplot des résolutions les plus représentées\n",
    "\n",
    "# Obtenir les 10 catégories les plus représentées\n",
    "categories = df_resolutions[\"image_size\"].value_counts().head(10).index\n",
    "# Créer une liste des noms des catégories\n",
    "noms_categories = []\n",
    "for categorie in categories:\n",
    "    noms_categories.append(categorie)\n",
    "noms_categories = list(reversed(noms_categories))\n",
    "# Créer une liste des valeurs des catégories\n",
    "valeurs_categories = []\n",
    "for categorie in categories:\n",
    "    valeurs_categories.append(df_resolutions[\"image_size\"].value_counts()[categorie] / len(df_resolutions))\n",
    "valeurs_categories = list(reversed(valeurs_categories))\n",
    "# Obtenir les valeurs des autres catégories\n",
    "autres_categories = df_resolutions[\"image_size\"].value_counts()[categories[-1]:].sum() / len(df_resolutions)\n",
    "# Créer une liste des valeurs des autres catégories\n",
    "valeurs_autres_categories = [autres_categories]\n",
    "# Créer un objet `Bar()`\n",
    "bar = plt.barh(noms_categories + [\"Autres\"], valeurs_categories + valeurs_autres_categories)\n",
    "# Définir les paramètres de l'objet `Bar()`\n",
    "plt.title(\"Les 10 résolutions les plus représentées\")\n",
    "plt.xlabel(\"Résolutions\")\n",
    "plt.ylabel(\"Fréquences\")\n",
    "# Afficher l'objet `Bar()`\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe827ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resolutions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96430a85",
   "metadata": {},
   "source": [
    "Afin de limiter le nombre d'images pour un entrainement, seules les images des 5 résolutions les plus représentées pourraient être conservées..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4809d9c",
   "metadata": {},
   "source": [
    "### Recherche de spécificitées sur les 10 formats principaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebb2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation des listes d'images de resolutions spécifiques\n",
    "r_320x240 = df_resolutions.loc[df_resolutions['image_size'] == '320x240', 'filename'].tolist()\n",
    "r_320x213 = df_resolutions.loc[df_resolutions['image_size'] == '320x213', 'filename'].tolist()\n",
    "r_320x214 = df_resolutions.loc[df_resolutions['image_size'] == '320x214', 'filename'].tolist()\n",
    "r_320x180 = df_resolutions.loc[df_resolutions['image_size'] == '320x180', 'filename'].tolist()\n",
    "r_320x212 = df_resolutions.loc[df_resolutions['image_size'] == '320x212', 'filename'].tolist()\n",
    "r_320x239 = df_resolutions.loc[df_resolutions['image_size'] == '320x239', 'filename'].tolist()\n",
    "r_320x320 = df_resolutions.loc[df_resolutions['image_size'] == '320x320', 'filename'].tolist()\n",
    "r_320x211 = df_resolutions.loc[df_resolutions['image_size'] == '320x211', 'filename'].tolist()\n",
    "r_320x241 = df_resolutions.loc[df_resolutions['image_size'] == '320x241', 'filename'].tolist()\n",
    "r_320x256 = df_resolutions.loc[df_resolutions['image_size'] == '320x256', 'filename'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fed457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation d'une grille d'images de resolutions 320x240\n",
    "IMAGE_DIR = full_images\n",
    "W, H = 224, 224\n",
    "show_gallery(r_320x240, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b8eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x213, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eebc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x214, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49eea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x180, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x212, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0724ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x239, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x320, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ffd8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x211, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72711c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x241, n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661b4b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_gallery(r_320x256, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba191dd",
   "metadata": {},
   "source": [
    "La résolution 320x320 contient en proportion beaucoup plus d'images prises au microscope que les autres résoutions, celle-ci pourrait être écartées ainsi que les résolutions contenant peu d'images (ne faisant pas partie des 5 premières). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2dbd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une liste d'images dont la résolution n'est pas dans les 10 résolutions les plus répandues ni 320x320\n",
    "liste_resolutions = ['320x240', '320x213', '320x214', '320x180', '320x212']\n",
    "df_resolutions_filtered = df_resolutions.loc[~df_resolutions['image_size'].isin(liste_resolutions)]\n",
    "resolutions_to_delete = df_resolutions_filtered['filename'].tolist()\n",
    "\n",
    "# mise à jour de la liste d'images à supprimer\n",
    "for filename in resolutions_to_delete:\n",
    "    images_to_delete.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb69c22",
   "metadata": {},
   "source": [
    "## Recherche d'identification de la cible (comestible) en fonction des canaux de couleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa11c5",
   "metadata": {},
   "source": [
    "### Analyse des canaux de couleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création d'une copie reduite du dataset pour l'étude des canaux de couleurs\n",
    "os.mkdir(full_images + '\\channels_study')\n",
    "dossier_destination = full_images + '\\channels_study'\n",
    "\n",
    "test_channels = os.listdir(full_images)\n",
    "test_channels = random.sample(test_channels, int(len(test_channels) / 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8064967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copie des images vers dossier_destination\n",
    "for image_name in test_channels:\n",
    "    original_image_path = os.path.join(full_images, image_name)\n",
    "    new_image_path = os.path.join(dossier_destination, image_name)\n",
    "    shutil.copy(original_image_path, new_image_path)\n",
    "\n",
    "# resize des images pou robtenir des dimensions homogènes\n",
    "W, H = 224, 224\n",
    "for file in os.listdir(dossier_destination):\n",
    "        image = cv2.imread(os.path.join(dossier_destination, file))\n",
    "        image_resize = cv2.resize(image, (W, H))\n",
    "        cv2.imwrite(os.path.join(dossier_destination, file), image_resize)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création du dataframe\n",
    "filename = os.listdir(dossier_destination)\n",
    "target = pd.read_csv(dataframe_dataset)\n",
    "target = target.drop(['kingdom', 'phylum', 'classes', 'order', 'family', 'genus', 'species'], axis = 1)\n",
    "target.rename(columns = {'image_lien' : 'filename'}, inplace =True)\n",
    "df = target.loc[target[\"filename\"].isin(filename)]\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5348f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une liste vide pour stocker les chemins d'accès complets\n",
    "paths = []\n",
    "# Itérer sur les fichiers du dossier\n",
    "for file in os.listdir(dossier_destination):\n",
    "    # Obtenir le chemin d'accès complet du fichier\n",
    "    path = os.path.join(dossier_destination, file)\n",
    "    # Ajouter le chemin d'accès complet à la liste\n",
    "    paths.append(path)\n",
    "    \n",
    "image_paths = paths\n",
    "data = np.empty((len(paths), W, H, 3))\n",
    "\n",
    "# Itérer sur les images\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    image = plt.imread(image_path)\n",
    "    image_array = image.reshape((W, H, 3))\n",
    "    data[i] = image_array\n",
    "    \n",
    "# Créer trois array NumPy vides\n",
    "red = np.empty((len(paths), W, H))\n",
    "green = np.empty((len(paths), W, H))\n",
    "blue = np.empty((len(paths), W, H))\n",
    "\n",
    "# Itérer sur les images et extraire les canaux de couleur\n",
    "for i in range(data.shape[0]):\n",
    "    red[i] = data[i, :, :, 0]\n",
    "    green[i] = data[i, :, :, 1]\n",
    "    blue[i] = data[i, :, :, 2]\n",
    "    \n",
    "# Créer un dictionnaire vide\n",
    "occurrences_red = {}\n",
    "occurrences_green = {}\n",
    "occurrences_blue = {}\n",
    "# Itérer sur les valeurs de l'array NumPy\n",
    "for value in red.flatten():\n",
    "    if value not in occurrences_red:\n",
    "        occurrences_red[value] = 0\n",
    "    occurrences_red[value] += 1\n",
    "for value in green.flatten():\n",
    "    if value not in occurrences_green:\n",
    "        occurrences_green[value] = 0\n",
    "    occurrences_green[value] += 1    \n",
    "for value in blue.flatten():\n",
    "    if value not in occurrences_blue:\n",
    "        occurrences_blue[value] = 0\n",
    "    occurrences_blue[value] += 1\n",
    "\n",
    "red_hist = {}\n",
    "for key in sorted(occurrences_red.keys()):\n",
    "    red_hist[key] = occurrences_red[key]\n",
    "red_list = list(red_hist.values())\n",
    "green_hist = {}\n",
    "for key in sorted(occurrences_green.keys()):\n",
    "    green_hist[key] = occurrences_green[key]\n",
    "green_list = list(green_hist.values())\n",
    "blue_hist = {}\n",
    "for key in sorted(occurrences_blue.keys()):\n",
    "    blue_hist[key] = occurrences_blue[key]\n",
    "blue_list = list(blue_hist.values())\n",
    "\n",
    "d = {'Red' : pd.Series(red_list), 'Green':pd.Series(green_list), 'Blue':pd.Series(blue_list)}\n",
    "df_RGBhist = pd.DataFrame(data = d)\n",
    "\n",
    "# création d'une figure permettant d'observer la répartition des valeurs des canaux\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.bar(df_RGBhist.index, df_RGBhist['Red'], color = 'red', alpha = 0.4)\n",
    "ax.bar(df_RGBhist.index, df_RGBhist['Green'], color = 'green', alpha = 0.4)\n",
    "ax.bar(df_RGBhist.index, df_RGBhist['Blue'], color = 'blue', alpha = 0.6)\n",
    "ax.set_xlabel('value')\n",
    "ax.yaxis.set_visible(False)\n",
    "ax.set_title('Répartition des valeurs des canaux de la base de données')\n",
    "plt.legend(['red', 'green', 'blue'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e591d9",
   "metadata": {},
   "source": [
    "Les 3 canaux de couleurs sont assez similaires, il ne semble pas opportun de supprimer l'un ou l'autre de ces canaux de la base de données d'images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2038888a",
   "metadata": {},
   "source": [
    "### Analyse des canaux de couleurs par catégorie pour la partie comestible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaec921",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.listdir(dossier_destination)\n",
    "# définir la cible pour charger le dataframe correspondant au dossier d'image complet avec les labels de l'étude\n",
    "target = pd.read_csv(dataframe_dataset)\n",
    "target = target.drop(['kingdom', 'phylum', 'classes', 'family', 'genus', 'species'], axis = 1)\n",
    "target.rename(columns = {'image_lien' : 'filename'}, inplace =True)\n",
    "df = target.loc[target[\"filename\"].isin(filename)]\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "#df.head()\n",
    "\n",
    "# création de sous_dossier catégoriels en fonction de la cible 'comestible'\n",
    "path_edible = os.path.join(dossier_destination, \"edible\")\n",
    "path_inedible = os.path.join(dossier_destination, \"inedible\")\n",
    "os.mkdir(path_edible)\n",
    "os.mkdir(path_inedible)\n",
    "\n",
    "# extraction des noms d'images du dataframe selon la colonne cible df['edible']\n",
    "# Sélection les lignes pour edible = 1 et edible = 0\n",
    "df_edible = df.loc[df[\"edible\"] == 1]\n",
    "df_inedible = df.loc[df[\"edible\"] == 0]\n",
    "\n",
    "# Extraction des noms des images dans des listes\n",
    "images_names_edible = df_edible[\"filename\"].values\n",
    "images_names_inedible = df_inedible[\"filename\"].values\n",
    "images_names_edible = list(images_names_edible)\n",
    "images_names_inedible = list(images_names_inedible)\n",
    "\n",
    "# copie des fichiers images vers les dossiers de destination\n",
    "for image_name in images_names_edible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(dossier_destination, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(path_edible, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "        \n",
    "for image_name in images_names_inedible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(dossier_destination, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(path_inedible, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "        \n",
    "# Créer un DataFrame contenant les valeurs des canaux de couleurs des images edible\n",
    "images_edible = os.listdir(path_edible)\n",
    "data_edible = []\n",
    "for image in images_edible:\n",
    "    image = plt.imread(os.path.join(path_edible, image))\n",
    "    r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    data_edible.append([np.mean(r), np.mean(g), np.mean(b)])\n",
    "df_edible = pd.DataFrame(data_edible, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "\n",
    "# Créer un DataFrame contenant les valeurs des canaux de couleurs des images inedible\n",
    "images_inedible = os.listdir(path_inedible)\n",
    "data_inedible = []\n",
    "for image in images_inedible:\n",
    "    image = plt.imread(os.path.join(path_inedible, image))\n",
    "    r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]\n",
    "    data_inedible.append([np.mean(r), np.mean(g), np.mean(b)])\n",
    "df_inedible = pd.DataFrame(data_inedible, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "# Création d'un violinplot représentant les canaux de couleur par label cible\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "# génération des données du violinplot\n",
    "data1 = df_edible['red'].tolist()\n",
    "data2 = df_edible['green'].tolist()\n",
    "data3 = df_edible['blue'].tolist()\n",
    "data4 = [300, 300, 300]\n",
    "data5 = df_inedible['red'].tolist()\n",
    "data6 = df_inedible['green'].tolist()\n",
    "data7 = df_inedible['blue'].tolist()\n",
    "\n",
    "# liste des données à ploter\n",
    "data = [data1, data2, data3, data4, data5, data6, data7]\n",
    "\n",
    "# définition de la couleur des violons\n",
    "colors = ['#FF0000', 'Green', 'Blue','White', '#FF0000', 'Green', 'Blue']\n",
    "ticks_colors = ['black','black','black','White','black','black','black',]\n",
    "# Creation du violinplot\n",
    "plots = ax.violinplot(data, vert=True, showmedians=True, showextrema=False, widths=1, showmeans=True)\n",
    "\n",
    "# Définition de paramtres personnalisés pour les violons\n",
    "for pc, color in zip(plots['bodies'], colors):\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_alpha(1)\n",
    "    pc.set_edgecolor('black')\n",
    "\n",
    "plots['cmedians'].set_colors(ticks_colors)\n",
    "plots['cmeans'].set_colors(ticks_colors)\n",
    "\n",
    "# Definition des paramètres de la figure\n",
    "ax.set_xticks([1, 2, 3, 4, 5, 6, 7], labels=['', 'Edible', '', '', '', 'Inedible', ''])\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_ylim(0, 256)\n",
    "\n",
    "# Ajout de la légende\n",
    "red_patch = mpatches.Patch(color='red', label='red')\n",
    "green_patch = mpatches.Patch(color='green', label='green')\n",
    "blue_patch = mpatches.Patch(color='blue', label='blue')\n",
    "ax.legend(handles=[red_patch, green_patch, blue_patch], loc = 'upper center', title = 'Channels', ncol = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8b69c",
   "metadata": {},
   "source": [
    "Les canaux RGB des cibles de l'étude sont assez similaires, il ne semble pas y avoir de corrélations entre les canaux de couleurs et la comestibilité des champignons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ba631",
   "metadata": {},
   "source": [
    "## Recherche d'identification de la cible (order) en fonction des canaux de couleurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516d065b",
   "metadata": {},
   "source": [
    "### Analyse des canaux de couleurs par catégorie pour la partie 'order'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d0dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.listdir(full_images)\n",
    "# définir la cible pour charger le dataframe correspondant au dossier d'image complet avec les labels de l'étude\n",
    "target = pd.read_csv(r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\dataset.csv')\n",
    "target = target.drop(['kingdom', 'phylum', 'classes', 'family', 'genus', 'species'], axis = 1)\n",
    "target = target.drop(target[target['edible'] == 0].index)\n",
    "target.rename(columns = {'image_lien' : 'filename'}, inplace =True)\n",
    "df = target.loc[target[\"filename\"].isin(filename)]\n",
    "df.reset_index(drop = True, inplace = True)\n",
    "#df.head()\n",
    "\n",
    "# Création d'une liste des catégories de 'order'\n",
    "order_list = df.order.unique()\n",
    "\n",
    "# Création du dossier et de la liste d'images à copier (max 2000 éléments tirés aléatoirement)\n",
    "for order in order_list :\n",
    "    path = os.path.join(full_images, order)\n",
    "    os.mkdir(path)\n",
    "    images_names = list(df.loc[df[\"order\"] == order, 'filename'])\n",
    "    if len(images_names) > 1500 :\n",
    "        images_names = random.sample(images_names, 1500)\n",
    "\n",
    "    \n",
    "    # copie des fichiers images vers les dossiers de destination\n",
    "    for image_name in images_names :    \n",
    "        # trouver l'image dans le dossier d'origine\n",
    "        original_image_path = os.path.join(full_images, image_name)\n",
    "        # copie de l'image dans le dossier de destination\n",
    "        new_image_path = os.path.join(path, image_name)\n",
    "        if os.path.exists(original_image_path):\n",
    "            image = PIL.Image.open(original_image_path)\n",
    "            if image.mode == 'RGB':\n",
    "                shutil.copy(original_image_path, new_image_path)\n",
    "\n",
    "        \n",
    "# Créer des DataFrames contenant les valeurs des canaux de couleurs des images de chaque catégorie\n",
    "order_list = df.order.unique()\n",
    "path = os.path.join(full_images, order_list[0])\n",
    "images = os.listdir(path)\n",
    "data = []\n",
    "for image in images:\n",
    "    image = plt.imread(os.path.join(path, image))\n",
    "    data.append([np.mean(image[:, :, 0]), np.mean(image[:, :, 1]), np.mean(image[:, :, 2])])\n",
    "Agaricales = pd.DataFrame(data, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "path = os.path.join(full_images, order_list[1])\n",
    "images = os.listdir(path)\n",
    "data = []\n",
    "for image in images:\n",
    "    image = plt.imread(os.path.join(path, image))\n",
    "    data.append([np.mean(image[:, :, 0]), np.mean(image[:, :, 1]), np.mean(image[:, :, 2])])\n",
    "Polyporales = pd.DataFrame(data, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "path = os.path.join(full_images, order_list[2])\n",
    "images = os.listdir(path)\n",
    "data = []\n",
    "for image in images:\n",
    "    image = plt.imread(os.path.join(path, image))\n",
    "    data.append([np.mean(image[:, :, 0]), np.mean(image[:, :, 1]), np.mean(image[:, :, 2])])\n",
    "Russulales = pd.DataFrame(data, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "path = os.path.join(full_images, order_list[3])\n",
    "images = os.listdir(path)\n",
    "data = []\n",
    "for image in images:\n",
    "    image = plt.imread(os.path.join(path, image))\n",
    "    data.append([np.mean(image[:, :, 0]), np.mean(image[:, :, 1]), np.mean(image[:, :, 2])])\n",
    "Gomphales = pd.DataFrame(data, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "path = os.path.join(full_images, order_list[4])\n",
    "images = os.listdir(path)\n",
    "data = []\n",
    "for image in images:\n",
    "    image = plt.imread(os.path.join(path, image))\n",
    "    data.append([np.mean(image[:, :, 0]), np.mean(image[:, :, 1]), np.mean(image[:, :, 2])])\n",
    "Pezizales = pd.DataFrame(data, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "path = os.path.join(full_images, order_list[5])\n",
    "images = os.listdir(path)\n",
    "data = []\n",
    "for image in images:\n",
    "    image = plt.imread(os.path.join(path, image))\n",
    "    data.append([np.mean(image[:, :, 0]), np.mean(image[:, :, 1]), np.mean(image[:, :, 2])])\n",
    "Boletales = pd.DataFrame(data, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "path = os.path.join(full_images, order_list[6])\n",
    "images = os.listdir(path)\n",
    "data = []\n",
    "for image in images:\n",
    "    image = plt.imread(os.path.join(path, image))\n",
    "    data.append([np.mean(image[:, :, 0]), np.mean(image[:, :, 1]), np.mean(image[:, :, 2])])\n",
    "Cantharellales = pd.DataFrame(data, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "path = os.path.join(full_images, order_list[7])\n",
    "images = os.listdir(path)\n",
    "data = []\n",
    "for image in images:\n",
    "    image = plt.imread(os.path.join(path, image))\n",
    "    data.append([np.mean(image[:, :, 0]), np.mean(image[:, :, 1]), np.mean(image[:, :, 2])])\n",
    "Auriculariales = pd.DataFrame(data, columns=[\"red\", \"green\", \"blue\"])\n",
    "\n",
    "# CRéation de la figure et des données du violinplot\n",
    "fig, ax = plt.subplots(1, 1, figsize = (9, 4))\n",
    "\n",
    "data1 = Agaricales['red'].tolist()\n",
    "data2 = Agaricales['green'].tolist()\n",
    "data3 = Agaricales['blue'].tolist()\n",
    "data4 = [300, 300, 300]\n",
    "data5 = Polyporales['red'].tolist()\n",
    "data6 = Polyporales['green'].tolist()\n",
    "data7 = Polyporales['blue'].tolist()\n",
    "data8 = [300, 300, 300]\n",
    "data9 = Russulales['red'].tolist()\n",
    "data10 = Russulales['green'].tolist()\n",
    "data11 = Russulales['blue'].tolist()\n",
    "data12 = [300, 300, 300]\n",
    "data13 = Gomphales['red'].tolist()\n",
    "data14 = Gomphales['green'].tolist()\n",
    "data15 = Gomphales['blue'].tolist()\n",
    "data16 = [300, 300, 300]\n",
    "data17 = Pezizales['red'].tolist()\n",
    "data18 = Pezizales['green'].tolist()\n",
    "data19 = Pezizales['blue'].tolist()\n",
    "data20 = [300, 300, 300]\n",
    "data21 = Boletales['red'].tolist()\n",
    "data22 = Boletales['green'].tolist()\n",
    "data23 = Boletales['blue'].tolist()\n",
    "data24 = [300, 300, 300]\n",
    "data25 = Cantharellales['red'].tolist()\n",
    "data26 = Cantharellales['green'].tolist()\n",
    "data27 = Cantharellales['blue'].tolist()\n",
    "data28 = [300, 300, 300]\n",
    "data29 = Auriculariales['red'].tolist()\n",
    "data30 = Auriculariales['green'].tolist()\n",
    "data31 = Auriculariales['blue'].tolist()\n",
    "\n",
    "# Creation de la liste des données a représenter\n",
    "data = [data1, data2, data3, data4, data5, data6, data7, data8, data9, data10,\n",
    "        data11, data12, data13, data14, data15, data16, data17, data18, data19, data20,\n",
    "        data21, data22, data23, data24, data25, data26, data27, data28, data29, data30,\n",
    "        data31]\n",
    "\n",
    "# Définition des couleurs des violons\n",
    "colors = ['Red', 'Green', 'Blue','White',\n",
    "          'Red', 'Green', 'Blue', 'White',\n",
    "         'Red', 'Green', 'Blue','White',\n",
    "         'Red', 'Green', 'Blue','White',\n",
    "         'Red', 'Green', 'Blue','White',\n",
    "         'Red', 'Green', 'Blue','White',\n",
    "         'Red', 'Green', 'Blue','White',\n",
    "         'Red', 'Green', 'Blue']\n",
    "ticks_colors = ['black','black','black','White',\n",
    "                'black','black','black','White',\n",
    "                'black','black','black','White',\n",
    "                'black','black','black','White',\n",
    "                'black','black','black','White',\n",
    "                'black','black','black','White',\n",
    "                'black','black','black','White',\n",
    "                'black','black','black',]\n",
    "\n",
    "# Creation du violinplot\n",
    "plots = ax.violinplot(data, vert=True, showmedians=True, showextrema=False, widths=1, showmeans=True)\n",
    "\n",
    "# Définition personnalisée des couleurs des violons\n",
    "for pc, color in zip(plots['bodies'], colors):\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_alpha(1)\n",
    "    pc.set_edgecolor('black')\n",
    "\n",
    "plots['cmedians'].set_colors(ticks_colors)\n",
    "plots['cmeans'].set_colors(ticks_colors)\n",
    "\n",
    "# Définition des labels de l'axe des x\n",
    "ax.set_xticks([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31],\n",
    "              labels=['', 'Agaricales', '', '',\n",
    "                      '', 'Polyporales', '', '',\n",
    "                     '', 'Russulales', '', '',\n",
    "                     '', 'Gomphales', '', '',\n",
    "                     '', 'Pezizales', '', '',\n",
    "                     '', 'Boletales', '', '',\n",
    "                     '', 'Cantharellales', '', '',\n",
    "                     '', 'Auriculariales', ''])\n",
    "\n",
    "# définition de quelques paramètres de la figure\n",
    "ax.xaxis.set_tick_params(labelsize = 8) \n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.set_visible(True)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_ylim(0, 256)\n",
    "\n",
    "# ajout de la légende\n",
    "red_patch = mpatches.Patch(color='red', label='red')\n",
    "green_patch = mpatches.Patch(color='green', label='green')\n",
    "blue_patch = mpatches.Patch(color='blue', label='blue')\n",
    "ax.legend(handles=[red_patch, green_patch, blue_patch], loc = 'upper center', title = 'Channels', ncol = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce57bd3",
   "metadata": {},
   "source": [
    "Les canaux RGB des cibles de l'étude sont assez similaires, il ne semble pas y avoir de corrélations entre les canaux de couleurs et la comestibilité des champignons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4781d6bf",
   "metadata": {},
   "source": [
    "# Nettoyage du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c35805",
   "metadata": {},
   "source": [
    "### Pour le dataset d'images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ea799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affichage du nonmbre d'élements à supprimer\n",
    "print(len(images_to_delete), \"images peuvent être supprimées du dataset d'images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dce9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des images\n",
    "files = os.listdir(full_images)\n",
    "for file in files:\n",
    "    if file in images_to_delete:\n",
    "        os.remove(os.path.join(full_images, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10ffc5",
   "metadata": {},
   "source": [
    "### Pour le dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(full_images)\n",
    "# mise à jour du dataframe\n",
    "df = pd.read_csv(dataframe_dataset)\n",
    "df_cleaned = df.loc[df['filename'].isin(files)]\n",
    "dossier_parent = os.path.dirname(full_images)\n",
    "df_cleaned.to_csv(f\"{dossier_parent}\\cleaned_cleaned_dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543bc3b7",
   "metadata": {},
   "source": [
    "#### Controle de la concordance des données et suppression des fichiers et dossiers créés pour cette étude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppression des sous-dossiers de full_images créés pour cette étude\n",
    "\n",
    "# Parcourir les dossiers du dossier\n",
    "for child in os.listdir(full_images):\n",
    "    # Obtenir le chemin du dossier enfant\n",
    "    chemin_dossier_enfant = os.path.join(full_images, child)\n",
    "\n",
    "    # Supprimer le dossier enfant et son contenu\n",
    "    try:\n",
    "        shutil.rmtree(chemin_dossier_enfant)\n",
    "    except OSError as e:\n",
    "        pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e31c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# controle de la correspondance entre le datafarme créé et le dossier d'images\n",
    "count = 0\n",
    "for file in os.listdir(full_images):\n",
    "    # Vérifier si le fichier est un sous-dossier\n",
    "    if not os.path.isdir(os.path.join(full_images, file)):\n",
    "        # Incrémenter le compteur\n",
    "        count += 1\n",
    "print(\"Le dataframe de l'étude contient\",len(df_cleaned),\"lignes\")\n",
    "print(\"Le dataset d'images contient\",count,\"images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
