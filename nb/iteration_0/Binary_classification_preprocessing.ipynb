{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69928a0c",
   "metadata": {},
   "source": [
    "# Notebook de classification binaire des images de champignons comestibles / non comestibles : preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed6cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# import du dataset complet\n",
    "df = pd.read_csv(r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\dataset.csv')\n",
    "\n",
    "# separation des images dans deux dossiers selon la cible (df['edible'])\n",
    "# definition des dossiers source et dossiers de destination\n",
    "source_dir = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\full_dataset\"\n",
    "target_dir_edible = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\edible\"\n",
    "target_dir_inedible = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\inedible\"\n",
    "\n",
    "# extraction des noms d'images du dataframe selon la colonne cible df['edible']\n",
    "# Sélection les lignes pour edible = 1 et edible = 0\n",
    "df_edible = df.loc[df[\"edible\"] == 1]\n",
    "df_inedible = df.loc[df[\"edible\"] == 0]\n",
    "\n",
    "# Extraction des noms des images dans des listes\n",
    "images_names_edible = df_edible[\"image_lien\"].values\n",
    "images_names_inedible = df_inedible[\"image_lien\"].values\n",
    "images_names_edible = list(images_names_edible)\n",
    "images_names_inedible = list(images_names_inedible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0422e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copie des fichiers images vers les dossiers de destination\n",
    "for image_name in images_names_edible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_edible, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "        \n",
    "for image_name in images_names_inedible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_inedible, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cb8531",
   "metadata": {},
   "source": [
    "# Creation des partitions Train / Validation / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fad104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "L'objectif est de créer 3 partitions du dataframe original :\n",
    "- Train : partition qui servira à l'entrainement du modèle de classification,\n",
    "- Validation : partition qui servira de set de validation lors de l'entraienemt du modèle,\n",
    "- Test : Partition qui ne verra jamais l'entrainement permettant de comparer différents modèles entre eux.\n",
    "\n",
    "Une premiere partition est créée depuis le dataset complet pour obtenir 'Test' représentant 20% des données d'origine,\n",
    "une seconde partition est ensuite créée depuis les données restantes permettant de créer Validation pour 20% de données restantes\n",
    "et Train 80% de données restantes.\n",
    "\n",
    "Au final, depuis les données d'origines les dataset représentent :\n",
    "Test (df_test) : 20%\n",
    "Validation (df_val) : 16%\n",
    "Train (df_train) : 64%\n",
    "\n",
    "Le random test de cette étude est 3\n",
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import du dataset complet\n",
    "df = pd.read_csv(r'C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\dataset.csv')\n",
    "\n",
    "# creation de la partition 'test' qui servira a tester le modele une fois celui-ci mis au point\n",
    "df_train_val, df_test = train_test_split(df, test_size=0.2, random_state = 3)\n",
    "\n",
    "# creation des partitions 'train' et 'val' qui serviront a entrainer et valider le modele \n",
    "df_train, df_val = train_test_split(df_train_val, test_size=0.2, random_state = 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a8141",
   "metadata": {},
   "source": [
    "# Creation de l'arborescence des fichiers images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a9e9d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import des librairies nécessaires\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# création des variable pour les dossiers sources et cible\n",
    "source_dir = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\full_images\"\n",
    "target_dir_train = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\train\"\n",
    "target_dir_val = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\validation\"\n",
    "target_dir_test = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\test\"\n",
    "\n",
    "# extraction des noms d'images des dataframes\n",
    "images_names_train = df_train['image_lien'].tolist()\n",
    "images_names_val = df_val['image_lien'].tolist()\n",
    "images_names_test = df_test['image_lien'].tolist()\n",
    "\n",
    "\n",
    "missing_picture_train = []\n",
    "missing_picture_val = []\n",
    "missing_picture_test = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8f7eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copie des images pour la partie train\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_train :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_train, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_train.append(picture)\n",
    "        \n",
    "# copie des images pour la partie validation\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_val :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_val, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_val.append(picture)      \n",
    "        \n",
    "# copie des images pour la partie test\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_test :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_test, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_test.append(picture)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a590d0c",
   "metadata": {},
   "source": [
    "# Creation des sous-repertoires d'images edible et inedible dans train et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30757783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# création des variables pour les dossiers sources\n",
    "source_dir_train = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\train\"\n",
    "source_dir_val = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\validation\"\n",
    "\n",
    "# création des dossiers edible et inedible dans les dossiers sources\n",
    "import os\n",
    "os.mkdir(os.path.join(source_dir_train, 'edible'))\n",
    "os.mkdir(os.path.join(source_dir_train, 'inedible'))\n",
    "os.mkdir(os.path.join(source_dir_val, 'edible'))\n",
    "os.mkdir(os.path.join(source_dir_val, 'inedible'))\n",
    "\n",
    "# création des variables pour les dossiers cibles\n",
    "target_dir_train_0 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\train\\inedible\"\n",
    "target_dir_train_1 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\train\\edible\"\n",
    "target_dir_val_0 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\validation\\inedible\"\n",
    "target_dir_val_1 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\validation\\edible\"\n",
    "\n",
    "# extraction des noms d'images du dataframe selon la colonne cible df['edible']\n",
    "# Sélection les lignes pour edible = 1 et edible = 0\n",
    "df_train_edible = df_train.loc[df_train[\"edible\"] == 1]\n",
    "df_train_inedible = df_train.loc[df_train[\"edible\"] == 0]\n",
    "df_val_edible = df_val.loc[df_val[\"edible\"] == 1]\n",
    "df_val_inedible = df_val.loc[df_val[\"edible\"] == 0]\n",
    "\n",
    "# Extraction des noms des images dans des listes\n",
    "images_names_train_edible = df_train_edible[\"image_lien\"].values\n",
    "images_names_train_inedible = df_train_inedible[\"image_lien\"].values\n",
    "images_names_train_edible = list(images_names_train_edible)\n",
    "images_names_train_inedible = list(images_names_train_inedible)\n",
    "\n",
    "images_names_val_edible = df_val_edible[\"image_lien\"].values\n",
    "images_names_val_inedible = df_val_inedible[\"image_lien\"].values\n",
    "images_names_val_edible = list(images_names_val_edible)\n",
    "images_names_val_inedible = list(images_names_val_inedible)\n",
    "\n",
    "\n",
    "missing_picture_train_1 = []\n",
    "missing_picture_train_0 = []\n",
    "missing_picture_val_1 = []\n",
    "missing_picture_val_0 = []\n",
    "\n",
    "# deplacement des images pour la partie train_edible\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_train_edible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir_train, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_train_1, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.move(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_train_1.append(picture)\n",
    "\n",
    "# deplacement des images pour la partie train_inedible\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_train_inedible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir_train, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_train_0, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.move(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_train_0.append(picture)\n",
    "        \n",
    "# deplacement des images pour la partie val_edible\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_val_edible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir_val, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_val_1, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.move(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_val_1.append(picture)\n",
    "\n",
    "# deplacement des images pour la partie val_inedible\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_val_inedible :    \n",
    "    # trouver l'image dans le dossier d'origine\n",
    "    original_image_path = os.path.join(source_dir_val, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_val_0, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.move(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_val_0.append(picture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e209f7",
   "metadata": {},
   "source": [
    "# Creation d'un jeu de données reduit pour faciliter l'étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76393b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# chemin du répertoire source initial\n",
    "source_dir_binary = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\"\n",
    "\n",
    "# Création de l'arborecence\n",
    "# Créer le dossier principal\n",
    "os.mkdir(os.path.join(source_dir_binary, 'reduced_dataset'))\n",
    "\n",
    "# Créer les trois sous-dossiers train, validation, test\n",
    "os.mkdir(os.path.join(source_dir_binary, 'reduced_dataset', 'train'))\n",
    "os.mkdir(os.path.join(source_dir_binary, 'reduced_dataset', 'test'))\n",
    "os.mkdir(os.path.join(source_dir_binary, 'reduced_dataset', 'validation'))\n",
    "\n",
    "# Créer les deux sous-sous-dossiers edible et inedible dans train et validation\n",
    "os.mkdir(os.path.join(source_dir_binary, 'reduced_dataset', 'train', 'edible'))\n",
    "os.mkdir(os.path.join(source_dir_binary, 'reduced_dataset', 'train', 'inedible'))\n",
    "os.mkdir(os.path.join(source_dir_binary, 'reduced_dataset', 'validation', 'edible'))\n",
    "os.mkdir(os.path.join(source_dir_binary, 'reduced_dataset', 'validation', 'inedible'))\n",
    "\n",
    "# sous-échantillonnage des dataframes\n",
    "df_train_edible_X = df_train_edible.sample(frac=0.1, random_state=3)\n",
    "df_train_inedible_X = df_train_inedible.sample(frac=0.1, random_state=3)\n",
    "df_val_edible_X = df_val_edible.sample(frac=0.1, random_state=3)\n",
    "df_val_inedible_X = df_val_inedible.sample(frac=0.1, random_state=3)\n",
    "df_test_X = df_test.sample(frac=0.1, random_state=3)\n",
    "\n",
    "# Création des listes d'images à déplacer\n",
    "images_names_train_edible_X = df_train_edible_X[\"image_lien\"].values\n",
    "images_names_train_inedible_X = df_train_inedible_X[\"image_lien\"].values\n",
    "images_names_train_edible_X = list(images_names_train_edible_X)\n",
    "images_names_train_inedible_X = list(images_names_train_inedible_X)\n",
    "\n",
    "images_names_val_edible_X = df_val_edible_X[\"image_lien\"].values\n",
    "images_names_val_inedible_X = df_val_inedible_X[\"image_lien\"].values\n",
    "images_names_val_edible_X = list(images_names_val_edible_X)\n",
    "images_names_val_inedible_X = list(images_names_val_inedible_X)\n",
    "\n",
    "images_names_test_X = df_test_X[\"image_lien\"].values\n",
    "images_names_test_X = list(images_names_test_X)\n",
    "\n",
    "missing_picture_train_X_1 =[]\n",
    "missing_picture_train_X_0 =[]\n",
    "missing_picture_val_X_1 =[]\n",
    "missing_picture_val_X_0 =[]\n",
    "missing_picture_test_X =[]\n",
    "\n",
    "# copie des images dans le dataset réduit\n",
    "# définition des dossiers sources\n",
    "source_dir_train_X_0 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\train\\inedible\"\n",
    "source_dir_train_X_1 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\train\\edible\"\n",
    "source_dir_val_X_0 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\validation\\inedible\"\n",
    "source_dir_val_X_1 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\validation\\edible\"\n",
    "source_dir_test_X = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\test\"\n",
    "\n",
    "# définition des dossiers cibles\n",
    "target_dir_train_X_0 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\reduced_dataset\\train\\inedible\"\n",
    "target_dir_train_X_1 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\reduced_dataset\\train\\edible\"\n",
    "target_dir_val_X_0 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\reduced_dataset\\validation\\inedible\"\n",
    "target_dir_val_X_1 = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\reduced_dataset\\validation\\edible\"\n",
    "target_dir_test_X = r\"C:\\Users\\renamedadmin\\Documents\\Formation_Datascience\\Projet_Datascientest_Champignons\\Dossier_technique\\02_Pieces_constitutives\\Dataset\\Binary_Classification\\reduced_dataset\\test\"\n",
    "\n",
    "# copie des images pour la partie train_edible_X\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_train_edible_X :    \n",
    "    # trouver l'image dans le dosssier d'origine\n",
    "    original_image_path = os.path.join(source_dir_train_X_1, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_train_X_1, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_train_X_1.append(picture)\n",
    "        \n",
    "# copie des images pour la partie train_inedible_X\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_train_inedible_X :    \n",
    "    # trouver l'image dans le dosssier d'origine\n",
    "    original_image_path = os.path.join(source_dir_train_X_0, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_train_X_0, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_train_X_0.append(picture)\n",
    "        \n",
    "# copie des images pour la partie val_edible_X\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_val_edible_X :    \n",
    "    # trouver l'image dans le dosssier d'origine\n",
    "    original_image_path = os.path.join(source_dir_val_X_1, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_val_X_1, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_val_X_1.append(picture)\n",
    "        \n",
    "# copie des images pour la partie val_inedible_X\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_val_inedible_X :    \n",
    "    # trouver l'image dans le dosssier d'origine\n",
    "    original_image_path = os.path.join(source_dir_val_X_0, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_val_X_0, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_val_X_0.append(picture)\n",
    "        \n",
    "# copie des images pour la partie test_X\n",
    "# itération sur les noms d'images\n",
    "for image_name in images_names_test_X :    \n",
    "    # trouver l'image dans le dosssier d'origine\n",
    "    original_image_path = os.path.join(source_dir_test_X, image_name)\n",
    "    # copie de l'image dans le dossier de destination\n",
    "    new_image_path = os.path.join(target_dir_test_X, image_name)\n",
    "    if os.path.exists(original_image_path):\n",
    "        shutil.copy(original_image_path, new_image_path)\n",
    "    else:\n",
    "        position_backslash = original_image_path.rfind(\"\\\\\")\n",
    "        picture = original_image_path[position_backslash + 1 :]\n",
    "        missing_picture_test_X.append(picture)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b2f5d",
   "metadata": {},
   "source": [
    "# Redimensionnement des images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cdcd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from PIL import Image\n",
    "\n",
    "# Largeur et hauteur des images redimensionnées\n",
    "largeur = 320\n",
    "hauteur = 320\n",
    "\n",
    "# Redimensionner les images de edible\n",
    "for fichier in os.listdir(target_dir_edible):\n",
    "    if os.path.isfile(os.path.join(target_dir_edible, fichier)) and fichier.endswith(\".jpg\"):\n",
    "        image = Image.open(os.path.join(target_dir_edible, fichier))\n",
    "        image = image.resize((largeur, hauteur))\n",
    "        image.save(os.path.join(target_dir_edible, fichier))\n",
    "        \n",
    "# Redimensionner les images de edible\n",
    "for fichier in os.listdir(target_dir_edible):\n",
    "    if os.path.isfile(os.path.join(target_dir_edible, fichier)) and fichier.endswith(\".jpg\"):\n",
    "        image = Image.open(os.path.join(target_dir_edible, fichier))\n",
    "        image = image.resize((largeur, hauteur))\n",
    "        image.save(os.path.join(target_dir_edible, fichier))\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6b311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b51bdc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
