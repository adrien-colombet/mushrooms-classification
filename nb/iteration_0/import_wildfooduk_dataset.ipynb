{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Wild Food UK dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset will be used as a separate validation dataset. It contains images of species not referenced in the main dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that to use the Kaggle API, you need to have a Kaggle account and a Kaggle API token. \n",
    "The token is a JSON file that you can download from your Kaggle account settings page. \n",
    "Once downloaded, place it in the location ~/.kaggle/kaggle.json on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/adrienc/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import kaggle\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_path = '../..'\n",
    "dataset_path = os.path.join(project_path, 'dataset', 'wildfooduk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/adrienc/.kaggle/kaggle.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-16 15:41:09,287 WARNING Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fbd682e46d0>, 'Connection to www.kaggle.com timed out. (connect timeout=None)')': /api/v1/datasets/download/daniilonishchenko/mushrooms-images-classification-215?datasetVersionNumber=None\n",
      "2023-09-16 15:43:20,359 WARNING Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fbd6820c790>, 'Connection to www.kaggle.com timed out. (connect timeout=None)')': /api/v1/datasets/download/daniilonishchenko/mushrooms-images-classification-215?datasetVersionNumber=None\n",
      "2023-09-16 15:45:31,431 WARNING Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fbd682e7fa0>, 'Connection to www.kaggle.com timed out. (connect timeout=None)')': /api/v1/datasets/download/daniilonishchenko/mushrooms-images-classification-215?datasetVersionNumber=None\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPSConnectionPool(host='www.kaggle.com', port=443): Max retries exceeded with url: /api/v1/datasets/download/daniilonishchenko/mushrooms-images-classification-215?datasetVersionNumber=None (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fbd682e7df0>, 'Connection to www.kaggle.com timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:169\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    170\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    171\u001b[0m     )\n\u001b[1;32m    173\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:96\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39mif\u001b[39;00m err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m     98\u001b[0m \u001b[39mraise\u001b[39;00m socket\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mgetaddrinfo returns an empty list\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:86\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     85\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 86\u001b[0m sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     87\u001b[0m \u001b[39mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:699\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    700\u001b[0m     conn,\n\u001b[1;32m    701\u001b[0m     method,\n\u001b[1;32m    702\u001b[0m     url,\n\u001b[1;32m    703\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    704\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    705\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    706\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    707\u001b[0m )\n\u001b[1;32m    709\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:382\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    384\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:1012\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1014\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:353\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    352\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    354\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m--> 174\u001b[0m     \u001b[39mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    175\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    176\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConnection to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m timed out. (connect timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    177\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout),\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    180\u001b[0m \u001b[39mexcept\u001b[39;00m SocketError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x7fbd682e7df0>, 'Connection to www.kaggle.com timed out. (connect timeout=None)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/adrienc/git/mushrooms-classification/nb/iteration_0/import_wildfooduk_dataset.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.106.43.178/home/adrienc/git/mushrooms-classification/nb/iteration_0/import_wildfooduk_dataset.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m kaggle\u001b[39m.\u001b[39mapi\u001b[39m.\u001b[39mauthenticate()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.106.43.178/home/adrienc/git/mushrooms-classification/nb/iteration_0/import_wildfooduk_dataset.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Download the dataset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.106.43.178/home/adrienc/git/mushrooms-classification/nb/iteration_0/import_wildfooduk_dataset.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m kaggle\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mdataset_download_files(\u001b[39m'\u001b[39;49m\u001b[39mdaniilonishchenko/mushrooms-images-classification-215\u001b[39;49m\u001b[39m'\u001b[39;49m, path\u001b[39m=\u001b[39;49mdataset_path, unzip\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle/api/kaggle_api_extended.py:1439\u001b[0m, in \u001b[0;36mKaggleApi.dataset_download_files\u001b[0;34m(self, dataset, path, force, quiet, unzip)\u001b[0m\n\u001b[1;32m   1435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1436\u001b[0m     effective_path \u001b[39m=\u001b[39m path\n\u001b[1;32m   1438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response(\n\u001b[0;32m-> 1439\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets_download_with_http_info(\n\u001b[1;32m   1440\u001b[0m         owner_slug\u001b[39m=\u001b[39;49mowner_slug,\n\u001b[1;32m   1441\u001b[0m         dataset_slug\u001b[39m=\u001b[39;49mdataset_slug,\n\u001b[1;32m   1442\u001b[0m         dataset_version_number\u001b[39m=\u001b[39;49mdataset_version_number,\n\u001b[1;32m   1443\u001b[0m         _preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m))\n\u001b[1;32m   1445\u001b[0m outfile \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(effective_path, dataset_slug \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1446\u001b[0m \u001b[39mif\u001b[39;00m force \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload_needed(response, outfile, quiet):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle/api/kaggle_api.py:1563\u001b[0m, in \u001b[0;36mKaggleApi.datasets_download_with_http_info\u001b[0;34m(self, owner_slug, dataset_slug, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m \u001b[39m# Authentication setting\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m auth_settings \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mbasicAuth\u001b[39m\u001b[39m'\u001b[39m]  \u001b[39m# noqa: E501\u001b[39;00m\n\u001b[0;32m-> 1563\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi_client\u001b[39m.\u001b[39;49mcall_api(\n\u001b[1;32m   1564\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39m/datasets/download/\u001b[39;49m\u001b[39m{ownerSlug}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{datasetSlug}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m   1565\u001b[0m     path_params,\n\u001b[1;32m   1566\u001b[0m     query_params,\n\u001b[1;32m   1567\u001b[0m     header_params,\n\u001b[1;32m   1568\u001b[0m     body\u001b[39m=\u001b[39;49mbody_params,\n\u001b[1;32m   1569\u001b[0m     post_params\u001b[39m=\u001b[39;49mform_params,\n\u001b[1;32m   1570\u001b[0m     files\u001b[39m=\u001b[39;49mlocal_var_files,\n\u001b[1;32m   1571\u001b[0m     response_type\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mResult\u001b[39;49m\u001b[39m'\u001b[39;49m,  \u001b[39m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m   1572\u001b[0m     auth_settings\u001b[39m=\u001b[39;49mauth_settings,\n\u001b[1;32m   1573\u001b[0m     async_req\u001b[39m=\u001b[39;49mparams\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39masync_req\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m   1574\u001b[0m     _return_http_data_only\u001b[39m=\u001b[39;49mparams\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m_return_http_data_only\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m   1575\u001b[0m     _preload_content\u001b[39m=\u001b[39;49mparams\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m_preload_content\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m),\n\u001b[1;32m   1576\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49mparams\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m_request_timeout\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m   1577\u001b[0m     collection_formats\u001b[39m=\u001b[39;49mcollection_formats)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle/api_client.py:329\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \n\u001b[1;32m    294\u001b[0m \u001b[39mTo make an async request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[39m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__call_api(resource_path, method,\n\u001b[1;32m    330\u001b[0m                            path_params, query_params, header_params,\n\u001b[1;32m    331\u001b[0m                            body, post_params, files,\n\u001b[1;32m    332\u001b[0m                            response_type, auth_settings,\n\u001b[1;32m    333\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[1;32m    334\u001b[0m                            _preload_content, _request_timeout)\n\u001b[1;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m     thread \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool\u001b[39m.\u001b[39mapply_async(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    337\u001b[0m                                    method, path_params, query_params,\n\u001b[1;32m    338\u001b[0m                                    header_params, body,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m                                    collection_formats,\n\u001b[1;32m    343\u001b[0m                                    _preload_content, _request_timeout))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle/api_client.py:161\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfiguration\u001b[39m.\u001b[39mhost \u001b[39m+\u001b[39m resource_path\n\u001b[1;32m    160\u001b[0m \u001b[39m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m response_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    162\u001b[0m     method, url, query_params\u001b[39m=\u001b[39;49mquery_params, headers\u001b[39m=\u001b[39;49mheader_params,\n\u001b[1;32m    163\u001b[0m     post_params\u001b[39m=\u001b[39;49mpost_params, body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    164\u001b[0m     _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    165\u001b[0m     _request_timeout\u001b[39m=\u001b[39;49m_request_timeout)\n\u001b[1;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_response \u001b[39m=\u001b[39m response_data\n\u001b[1;32m    169\u001b[0m return_data \u001b[39m=\u001b[39m response_data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle/api_client.py:351\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Makes the HTTP request using RESTClient.\"\"\"\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 351\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrest_client\u001b[39m.\u001b[39;49mGET(url,\n\u001b[1;32m    352\u001b[0m                                 query_params\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    353\u001b[0m                                 _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    354\u001b[0m                                 _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    355\u001b[0m                                 headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    356\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHEAD\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    357\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrest_client\u001b[39m.\u001b[39mHEAD(url,\n\u001b[1;32m    358\u001b[0m                                  query_params\u001b[39m=\u001b[39mquery_params,\n\u001b[1;32m    359\u001b[0m                                  _preload_content\u001b[39m=\u001b[39m_preload_content,\n\u001b[1;32m    360\u001b[0m                                  _request_timeout\u001b[39m=\u001b[39m_request_timeout,\n\u001b[1;32m    361\u001b[0m                                  headers\u001b[39m=\u001b[39mheaders)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle/rest.py:247\u001b[0m, in \u001b[0;36mRESTClientObject.GET\u001b[0;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mGET\u001b[39m(\u001b[39mself\u001b[39m, url, headers\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, query_params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, _preload_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m         _request_timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 247\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, url,\n\u001b[1;32m    248\u001b[0m                         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    249\u001b[0m                         _preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    250\u001b[0m                         _request_timeout\u001b[39m=\u001b[39;49m_request_timeout,\n\u001b[1;32m    251\u001b[0m                         query_params\u001b[39m=\u001b[39;49mquery_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/kaggle/rest.py:220\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[39mraise\u001b[39;00m ApiException(status\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, reason\u001b[39m=\u001b[39mmsg)\n\u001b[1;32m    218\u001b[0m     \u001b[39m# For `GET`, `HEAD`\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m         r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpool_manager\u001b[39m.\u001b[39;49mrequest(method, url,\n\u001b[1;32m    221\u001b[0m                                       fields\u001b[39m=\u001b[39;49mquery_params,\n\u001b[1;32m    222\u001b[0m                                       preload_content\u001b[39m=\u001b[39;49m_preload_content,\n\u001b[1;32m    223\u001b[0m                                       timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    224\u001b[0m                                       headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    225\u001b[0m \u001b[39mexcept\u001b[39;00m urllib3\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mSSLError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    226\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(e)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/request.py:74\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     71\u001b[0m urlopen_kw[\u001b[39m\"\u001b[39m\u001b[39mrequest_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m url\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encode_url_methods:\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/request.py:96\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m fields:\n\u001b[1;32m     94\u001b[0m     url \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m urlencode(fields)\n\u001b[0;32m---> 96\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/poolmanager.py:375\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    373\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 375\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    377\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:783\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[1;32m    779\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    781\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    782\u001b[0m     )\n\u001b[0;32m--> 783\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    784\u001b[0m         method,\n\u001b[1;32m    785\u001b[0m         url,\n\u001b[1;32m    786\u001b[0m         body,\n\u001b[1;32m    787\u001b[0m         headers,\n\u001b[1;32m    788\u001b[0m         retries,\n\u001b[1;32m    789\u001b[0m         redirect,\n\u001b[1;32m    790\u001b[0m         assert_same_host,\n\u001b[1;32m    791\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    792\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    793\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    794\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    795\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    796\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[1;32m    797\u001b[0m     )\n\u001b[1;32m    799\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    800\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:783\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[1;32m    779\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    781\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    782\u001b[0m     )\n\u001b[0;32m--> 783\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    784\u001b[0m         method,\n\u001b[1;32m    785\u001b[0m         url,\n\u001b[1;32m    786\u001b[0m         body,\n\u001b[1;32m    787\u001b[0m         headers,\n\u001b[1;32m    788\u001b[0m         retries,\n\u001b[1;32m    789\u001b[0m         redirect,\n\u001b[1;32m    790\u001b[0m         assert_same_host,\n\u001b[1;32m    791\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    792\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    793\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    794\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    795\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    796\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[1;32m    797\u001b[0m     )\n\u001b[1;32m    799\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    800\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:783\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn:\n\u001b[1;32m    779\u001b[0m     \u001b[39m# Try again\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     log\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    781\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRetrying (\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m) after connection broken by \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, retries, err, url\n\u001b[1;32m    782\u001b[0m     )\n\u001b[0;32m--> 783\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    784\u001b[0m         method,\n\u001b[1;32m    785\u001b[0m         url,\n\u001b[1;32m    786\u001b[0m         body,\n\u001b[1;32m    787\u001b[0m         headers,\n\u001b[1;32m    788\u001b[0m         retries,\n\u001b[1;32m    789\u001b[0m         redirect,\n\u001b[1;32m    790\u001b[0m         assert_same_host,\n\u001b[1;32m    791\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    792\u001b[0m         pool_timeout\u001b[39m=\u001b[39;49mpool_timeout,\n\u001b[1;32m    793\u001b[0m         release_conn\u001b[39m=\u001b[39;49mrelease_conn,\n\u001b[1;32m    794\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    795\u001b[0m         body_pos\u001b[39m=\u001b[39;49mbody_pos,\n\u001b[1;32m    796\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw\n\u001b[1;32m    797\u001b[0m     )\n\u001b[1;32m    799\u001b[0m \u001b[39m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    800\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:755\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(e, (SocketError, HTTPException)):\n\u001b[1;32m    753\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[0;32m--> 755\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[1;32m    756\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m    757\u001b[0m )\n\u001b[1;32m    758\u001b[0m retries\u001b[39m.\u001b[39msleep()\n\u001b[1;32m    760\u001b[0m \u001b[39m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/retry.py:574\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    563\u001b[0m new_retry \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew(\n\u001b[1;32m    564\u001b[0m     total\u001b[39m=\u001b[39mtotal,\n\u001b[1;32m    565\u001b[0m     connect\u001b[39m=\u001b[39mconnect,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    570\u001b[0m     history\u001b[39m=\u001b[39mhistory,\n\u001b[1;32m    571\u001b[0m )\n\u001b[1;32m    573\u001b[0m \u001b[39mif\u001b[39;00m new_retry\u001b[39m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 574\u001b[0m     \u001b[39mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[39mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    576\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mIncremented Retry for (url=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m): \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m, url, new_retry)\n\u001b[1;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m new_retry\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='www.kaggle.com', port=443): Max retries exceeded with url: /api/v1/datasets/download/daniilonishchenko/mushrooms-images-classification-215?datasetVersionNumber=None (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7fbd682e7df0>, 'Connection to www.kaggle.com timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "# Authenticate with your Kaggle account\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "# Download the dataset\n",
    "kaggle.api.dataset_download_files('daniilonishchenko/mushrooms-images-classification-215', path=dataset_path, unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying scientific name of complementary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_name</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>edibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>almond_mushroom</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amanita_gemmata</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amethyst_chanterelle</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>amethyst_deceiver</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aniseed_funnel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            common_name scientific_name edibility\n",
       "0       almond_mushroom                          \n",
       "1       amanita_gemmata                          \n",
       "2  amethyst_chanterelle                          \n",
       "3     amethyst_deceiver                          \n",
       "4        aniseed_funnel                          "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only common names are indicated. \n",
    "# creating a dataframe common english name\n",
    "\n",
    "# List of common names\n",
    "reference_table = pd.read_csv(os.path.join(dataset_path, 'mushrooms.txt'), names=['common_name']  )\n",
    "reference_table['scientific_name'] = ''\n",
    "reference_table['edibility'] = ''\n",
    "reference_table.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Make a GET request to the website\n",
    "response = requests.get('https://www.wildfooduk.com/mushroom-guide/')\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all the <td> elements with class=\"spotlight-text\"\n",
    "td_elements = soup.find_all('td', class_='spotlight-text')\n",
    "\n",
    "# Extract the text from each <td> element\n",
    "scientific_names  = [td.text.strip() for td in td_elements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the <td> elements with class=\"mushroom-image\"\n",
    "td_elements = soup.find_all('td', class_='mushroom-image')\n",
    "\n",
    "# Find all the <img> elements within the <td> element\n",
    "img_elements = [td.find('img') for td in td_elements] \n",
    "\n",
    "# Extract the text from each <td> element\n",
    "common_names  = [img.get('alt') for img in img_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the <td> elements with class=\"mushroom-icon\"\n",
    "td_elements = soup.find_all('td', class_='mushroom-icon')\n",
    "\n",
    "# Find all the <img> elements within the <td> element\n",
    "img_elements = [td.find('img') for td in td_elements] \n",
    "\n",
    "# Extract the text from each <td> element\n",
    "edibility  = [img.get('alt') for img in img_elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>common_name</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>edibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Blushing Rosette</td>\n",
       "      <td>Abortiporus biennis</td>\n",
       "      <td>Inedible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Horse Mushroom</td>\n",
       "      <td>Agaricus arvensis</td>\n",
       "      <td>Edible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Prince</td>\n",
       "      <td>Agaricus augustus</td>\n",
       "      <td>Edible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pavement Mushroom</td>\n",
       "      <td>Agaricus bitorquis</td>\n",
       "      <td>Edible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Medusa Mushroom</td>\n",
       "      <td>Agaricus bohusii</td>\n",
       "      <td>Edible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         common_name      scientific_name edibility\n",
       "0   Blushing Rosette  Abortiporus biennis  Inedible\n",
       "1     Horse Mushroom    Agaricus arvensis    Edible\n",
       "2         The Prince    Agaricus augustus    Edible\n",
       "3  Pavement Mushroom   Agaricus bitorquis    Edible\n",
       "4    Medusa Mushroom     Agaricus bohusii    Edible"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_table = pd.DataFrame({'common_name': common_names, 'scientific_name': scientific_names, 'edibility' : edibility})\n",
    "reference_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_table['edibility'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_table['edibility'] = reference_table['edibility'].replace({'Edible': 1, 'Poisonous': 0, 'Inedible': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edibility\n",
       "1    125\n",
       "0     97\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_table['edibility'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_table['common_name'] = reference_table['common_name'].str.split('/').str[-1].str.lstrip().str.rstrip().str.replace('.',\"\").str.replace(\"'\",\"\").str.replace(\"-\",\" \")\n",
    "reference_table['scientific_name'] = reference_table['scientific_name'].str.split('/').str[-1].str.lstrip().str.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_table.to_csv('../../dataset/wildfooduk_mapping_table.csv', index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross analysing base dataset and complementary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3627943/1333033861.py:1: DtypeWarning: Columns (2,5,25,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../../dataset/observations_mushroom.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_lien</th>\n",
       "      <th>image_id</th>\n",
       "      <th>observation</th>\n",
       "      <th>label</th>\n",
       "      <th>image_url</th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>gbif_info/kingdom</th>\n",
       "      <th>gbif_info/family</th>\n",
       "      <th>gbif_info/speciesKey</th>\n",
       "      <th>...</th>\n",
       "      <th>gbif_info/phylumKey</th>\n",
       "      <th>gbif_info/class</th>\n",
       "      <th>gbif_info/synonym</th>\n",
       "      <th>gbif_info/scientificName</th>\n",
       "      <th>gbif_info/genus</th>\n",
       "      <th>gbif_info/order</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>location</th>\n",
       "      <th>gbif_info/note</th>\n",
       "      <th>gbif_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Xylaria polymorpha</td>\n",
       "      <td>http://mushroomobserver.org/images/320/1</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-05-21 07:17:05</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Xylariaceae</td>\n",
       "      <td>5255104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Sordariomycetes</td>\n",
       "      <td>False</td>\n",
       "      <td>Xylaria polymorpha (Pers.) Grev., 1824</td>\n",
       "      <td>Xylaria</td>\n",
       "      <td>Xylariales</td>\n",
       "      <td>1</td>\n",
       "      <td>214.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Xylaria magnoliae</td>\n",
       "      <td>http://mushroomobserver.org/images/320/2</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-05-21 07:17:06</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Xylariaceae</td>\n",
       "      <td>3461845.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Sordariomycetes</td>\n",
       "      <td>False</td>\n",
       "      <td>Xylaria magnoliae J.D. Rogers, 1979</td>\n",
       "      <td>Xylaria</td>\n",
       "      <td>Xylariales</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Xylaria hypoxylon</td>\n",
       "      <td>http://mushroomobserver.org/images/320/3</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-05-21 07:17:08</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Xylariaceae</td>\n",
       "      <td>8631710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Sordariomycetes</td>\n",
       "      <td>False</td>\n",
       "      <td>Xylaria hypoxylon (L.) Grev., 1824</td>\n",
       "      <td>Xylaria</td>\n",
       "      <td>Xylariales</td>\n",
       "      <td>1</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Xylaria hypoxylon</td>\n",
       "      <td>http://mushroomobserver.org/images/320/4</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-05-21 07:17:10</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Xylariaceae</td>\n",
       "      <td>8631710.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Sordariomycetes</td>\n",
       "      <td>False</td>\n",
       "      <td>Xylaria hypoxylon (L.) Grev., 1824</td>\n",
       "      <td>Xylaria</td>\n",
       "      <td>Xylariales</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Xeromphalina</td>\n",
       "      <td>http://mushroomobserver.org/images/320/5</td>\n",
       "      <td>1</td>\n",
       "      <td>2006-05-21 07:17:12</td>\n",
       "      <td>Fungi</td>\n",
       "      <td>Mycenaceae</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>False</td>\n",
       "      <td>Xeromphalina Khner &amp; Maire</td>\n",
       "      <td>Xeromphalina</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_lien  image_id observation               label  \\\n",
       "0      1.jpg         1           1  Xylaria polymorpha   \n",
       "1      2.jpg         2           2   Xylaria magnoliae   \n",
       "2      3.jpg         3           3   Xylaria hypoxylon   \n",
       "3      4.jpg         4           4   Xylaria hypoxylon   \n",
       "4      5.jpg         5           5        Xeromphalina   \n",
       "\n",
       "                                  image_url user                 date  \\\n",
       "0  http://mushroomobserver.org/images/320/1    1  2006-05-21 07:17:05   \n",
       "1  http://mushroomobserver.org/images/320/2    1  2006-05-21 07:17:06   \n",
       "2  http://mushroomobserver.org/images/320/3    1  2006-05-21 07:17:08   \n",
       "3  http://mushroomobserver.org/images/320/4    1  2006-05-21 07:17:10   \n",
       "4  http://mushroomobserver.org/images/320/5    1  2006-05-21 07:17:12   \n",
       "\n",
       "  gbif_info/kingdom gbif_info/family  gbif_info/speciesKey  ...  \\\n",
       "0             Fungi      Xylariaceae             5255104.0  ...   \n",
       "1             Fungi      Xylariaceae             3461845.0  ...   \n",
       "2             Fungi      Xylariaceae             8631710.0  ...   \n",
       "3             Fungi      Xylariaceae             8631710.0  ...   \n",
       "4             Fungi       Mycenaceae                   NaN  ...   \n",
       "\n",
       "  gbif_info/phylumKey  gbif_info/class  gbif_info/synonym  \\\n",
       "0                95.0  Sordariomycetes              False   \n",
       "1                95.0  Sordariomycetes              False   \n",
       "2                95.0  Sordariomycetes              False   \n",
       "3                95.0  Sordariomycetes              False   \n",
       "4                34.0   Agaricomycetes              False   \n",
       "\n",
       "                 gbif_info/scientificName  gbif_info/genus  gbif_info/order  \\\n",
       "0  Xylaria polymorpha (Pers.) Grev., 1824          Xylaria       Xylariales   \n",
       "1     Xylaria magnoliae J.D. Rogers, 1979          Xylaria       Xylariales   \n",
       "2      Xylaria hypoxylon (L.) Grev., 1824          Xylaria       Xylariales   \n",
       "3      Xylaria hypoxylon (L.) Grev., 1824          Xylaria       Xylariales   \n",
       "4             Xeromphalina Khner & Maire     Xeromphalina       Agaricales   \n",
       "\n",
       "  thumbnail  location gbif_info/note  gbif_info  \n",
       "0         1     214.0            NaN        NaN  \n",
       "1         1      53.0            NaN        NaN  \n",
       "2         1      60.0            NaN        NaN  \n",
       "3         1       5.0            NaN        NaN  \n",
       "4         1      36.0            NaN        NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../dataset/observations_mushroom.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species not present in the initial dataset\n",
      "-------------------------------------------\n",
      "Agaricus bohusii\n",
      "Amanita citrina var. alba\n",
      "Amanita citrina var. citrina\n",
      "Hortiboletus bubalinus\n",
      "Neoboletus praestigiator\n",
      "Xerocomellus porosporus\n",
      "Boletus reticulatus\n",
      "Thaxterogaster purpurascens\n",
      "Hapalopilus rutilans\n",
      "Heboloma crustuliniforme\n",
      "Gliophorus reginae\n",
      "Porpolomopsis calyptriformis\n",
      "Inosperma erubescens\n",
      "Jackrogersella multiformis\n",
      "Lactifluus vellereus\n",
      "Apioperdon pyriforme\n",
      "Mucidula mucida\n",
      "Russula undulata\n",
      "Scleroderma spp.\n",
      "-------------------------------------------\n",
      "matching species count: 203\n"
     ]
    }
   ],
   "source": [
    "\n",
    "match_count = 0\n",
    "print(\"species not present in the initial dataset\")\n",
    "print(\"-------------------------------------------\")   \n",
    "\n",
    "for element in reference_table['scientific_name'].unique():\n",
    "    if element in df['label'].unique():\n",
    "        match_count = match_count + 1\n",
    "    else:\n",
    "        print(element)\n",
    "\n",
    "print(\"-------------------------------------------\")        \n",
    "print(\"matching species count: \" + str(match_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding identified species into the edible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edible mushrooms of the imported dataset will be filtered to be added in the edible dataset\n",
    "# images will get a unique identifier not already used by the existing dataset starting from 1 000 000 for clarity\n",
    "# only the scientific name has been deduced. The reste of the data frame needs also to be filled\n",
    "# images are converted to jpeg for homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_lien</th>\n",
       "      <th>image_id</th>\n",
       "      <th>family</th>\n",
       "      <th>rank</th>\n",
       "      <th>phylum</th>\n",
       "      <th>species</th>\n",
       "      <th>confidence</th>\n",
       "      <th>matchType</th>\n",
       "      <th>status</th>\n",
       "      <th>canonicalName</th>\n",
       "      <th>class</th>\n",
       "      <th>synonym</th>\n",
       "      <th>scientificName</th>\n",
       "      <th>genus</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.jpg</td>\n",
       "      <td>16</td>\n",
       "      <td>Pluteaceae</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Volvopluteus gloiocephalus</td>\n",
       "      <td>98.0</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>Volvopluteus gloiocephalus</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>False</td>\n",
       "      <td>Volvopluteus gloiocephalus (DC.) Vizzini, Cont...</td>\n",
       "      <td>Volvopluteus</td>\n",
       "      <td>Agaricales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54.jpg</td>\n",
       "      <td>54</td>\n",
       "      <td>Tricholomataceae</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Tricholoma atrosquamosum</td>\n",
       "      <td>98.0</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>Tricholoma atrosquamosum</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>False</td>\n",
       "      <td>Tricholoma atrosquamosum Sacc., 1887</td>\n",
       "      <td>Tricholoma</td>\n",
       "      <td>Agaricales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55.jpg</td>\n",
       "      <td>55</td>\n",
       "      <td>Tricholomataceae</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Tricholoma atrosquamosum</td>\n",
       "      <td>98.0</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>ACCEPTED</td>\n",
       "      <td>Tricholoma atrosquamosum</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>False</td>\n",
       "      <td>Tricholoma atrosquamosum Sacc., 1887</td>\n",
       "      <td>Tricholoma</td>\n",
       "      <td>Agaricales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.jpg</td>\n",
       "      <td>95</td>\n",
       "      <td>Sparassidaceae</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Sparassis crispa</td>\n",
       "      <td>98.0</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>SYNONYM</td>\n",
       "      <td>Sparassis radicata</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>True</td>\n",
       "      <td>Sparassis radicata Weir, 1917</td>\n",
       "      <td>Sparassis</td>\n",
       "      <td>Polyporales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94.jpg</td>\n",
       "      <td>94</td>\n",
       "      <td>Sparassidaceae</td>\n",
       "      <td>SPECIES</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Sparassis crispa</td>\n",
       "      <td>98.0</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>SYNONYM</td>\n",
       "      <td>Sparassis radicata</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>True</td>\n",
       "      <td>Sparassis radicata Weir, 1917</td>\n",
       "      <td>Sparassis</td>\n",
       "      <td>Polyporales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_lien  image_id            family     rank         phylum  \\\n",
       "0     16.jpg        16        Pluteaceae  SPECIES  Basidiomycota   \n",
       "1     54.jpg        54  Tricholomataceae  SPECIES  Basidiomycota   \n",
       "2     55.jpg        55  Tricholomataceae  SPECIES  Basidiomycota   \n",
       "3     95.jpg        95    Sparassidaceae  SPECIES  Basidiomycota   \n",
       "4     94.jpg        94    Sparassidaceae  SPECIES  Basidiomycota   \n",
       "\n",
       "                      species  confidence matchType    status  \\\n",
       "0  Volvopluteus gloiocephalus        98.0     EXACT  ACCEPTED   \n",
       "1    Tricholoma atrosquamosum        98.0     EXACT  ACCEPTED   \n",
       "2    Tricholoma atrosquamosum        98.0     EXACT  ACCEPTED   \n",
       "3            Sparassis crispa        98.0     EXACT   SYNONYM   \n",
       "4            Sparassis crispa        98.0     EXACT   SYNONYM   \n",
       "\n",
       "                canonicalName           class  synonym  \\\n",
       "0  Volvopluteus gloiocephalus  Agaricomycetes    False   \n",
       "1    Tricholoma atrosquamosum  Agaricomycetes    False   \n",
       "2    Tricholoma atrosquamosum  Agaricomycetes    False   \n",
       "3          Sparassis radicata  Agaricomycetes     True   \n",
       "4          Sparassis radicata  Agaricomycetes     True   \n",
       "\n",
       "                                      scientificName         genus  \\\n",
       "0  Volvopluteus gloiocephalus (DC.) Vizzini, Cont...  Volvopluteus   \n",
       "1               Tricholoma atrosquamosum Sacc., 1887    Tricholoma   \n",
       "2               Tricholoma atrosquamosum Sacc., 1887    Tricholoma   \n",
       "3                      Sparassis radicata Weir, 1917     Sparassis   \n",
       "4                      Sparassis radicata Weir, 1917     Sparassis   \n",
       "\n",
       "         order  \n",
       "0   Agaricales  \n",
       "1   Agaricales  \n",
       "2   Agaricales  \n",
       "3  Polyporales  \n",
       "4  Polyporales  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edible = pd.read_csv('../../dataset/order_classification/edible_mushrooms.csv')\n",
    "df_edible.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Volvopluteus gloiocephalus</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Pluteaceae</td>\n",
       "      <td>Volvopluteus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tricholoma atrosquamosum</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Tricholomataceae</td>\n",
       "      <td>Tricholoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sparassis crispa</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Polyporales</td>\n",
       "      <td>Sparassidaceae</td>\n",
       "      <td>Sparassis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Russula virescens</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Russulales</td>\n",
       "      <td>Russulaceae</td>\n",
       "      <td>Russula</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russula cyanoxantha</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Russulales</td>\n",
       "      <td>Russulaceae</td>\n",
       "      <td>Russula</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      species         phylum           class        order  \\\n",
       "0  Volvopluteus gloiocephalus  Basidiomycota  Agaricomycetes   Agaricales   \n",
       "1    Tricholoma atrosquamosum  Basidiomycota  Agaricomycetes   Agaricales   \n",
       "3            Sparassis crispa  Basidiomycota  Agaricomycetes  Polyporales   \n",
       "5           Russula virescens  Basidiomycota  Agaricomycetes   Russulales   \n",
       "6         Russula cyanoxantha  Basidiomycota  Agaricomycetes   Russulales   \n",
       "\n",
       "             family         genus  \n",
       "0        Pluteaceae  Volvopluteus  \n",
       "1  Tricholomataceae    Tricholoma  \n",
       "3    Sparassidaceae     Sparassis  \n",
       "5       Russulaceae       Russula  \n",
       "6       Russulaceae       Russula  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classes = df_edible.drop(columns = ['image_lien', 'image_id'])\n",
    "df_classes = df_classes[[ 'species','phylum', 'class', 'order', 'family','genus']].drop_duplicates()\n",
    "df_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling exceptions:\n",
    "name_exceptions = {\n",
    "\"blackening polypore\" : \"giant polypore\",\n",
    "\"cauliflower fungus\" : \"wood cauliflower\",\n",
    "\"clouded agaric\" : \"clouded funnel\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviewing possibles matches : common name, synonyms, and scientific name used as a common name\n",
    "\n",
    "def find_scientific_name(common_name, reference_table, name_exceptions):\n",
    "    try:\n",
    "        scientific_name = reference_table[reference_table['common_name'].str.lower() == common_name]['scientific_name'].iloc[0]\n",
    "    except:\n",
    "        try:\n",
    "            scientific_name = reference_table[reference_table['scientific_name'].str.lower() == common_name]['scientific_name'].iloc[0]\n",
    "        except:\n",
    "            try:\n",
    "                synonym = name_exceptions[common_name.lower()]\n",
    "                scientific_name = reference_table[reference_table['common_name'].str.lower() == synonym]['scientific_name'].iloc[0]\n",
    "            except:\n",
    "                print( \"not found : \" + common_name)   \n",
    "                scientific_name = \"\"\n",
    "    return scientific_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia_page(mushroom_name):\n",
    "\n",
    "    # Preparing classification\n",
    "    classification = dict()\n",
    "    classification[\"species\"] = mushroom_name\n",
    "\n",
    "    # Replace spaces in the mushroom name with underscores to match Wikipedia's URL format\n",
    "    mushroom_name = mushroom_name.replace(' ', '_')\n",
    "\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(f\"https://en.wikipedia.org/wiki/{mushroom_name}\")\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to get page: {response.status_code} \" + \" for \" + mushroom_name)\n",
    "        return\n",
    "\n",
    "    # Parse the page content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find the title of the page\n",
    "    title = soup.find(id=\"firstHeading\")\n",
    "\n",
    "    # Print the title\n",
    "    #print(title.string)\n",
    "\n",
    "    # Find the table with the scientific classification\n",
    "    rows = soup.find_all('td')\n",
    "\n",
    "    # Iterate over each row\n",
    "    iterator = iter(rows)\n",
    "    for row in iterator:\n",
    "        #print(repr(row.text.replace(\":\",\"\").rstrip()))\n",
    "        if(row.text.replace(\":\",\"\").rstrip() == \"Division\"):\n",
    "            classification[\"phylum\"] = next(iterator).text.strip()\n",
    "\n",
    "        if(row.text.replace(\":\",\"\").rstrip() == \"Class\"):\n",
    "            classification[\"class\"] = next(iterator).text.strip()\n",
    "        \n",
    "        if(row.text.replace(\":\",\"\").rstrip() == \"Order\"):\n",
    "            classification[\"order\"] = next(iterator).text.strip()\n",
    "\n",
    "        if(row.text.replace(\":\",\"\").rstrip() == \"Family\"):\n",
    "            classification[\"family\"] = next(iterator).text.strip()\n",
    "\n",
    "        if(row.text.replace(\":\",\"\").rstrip() == \"Genus\"):\n",
    "            classification[\"genus\"] = next(iterator).text.strip()\n",
    "\n",
    "    # Check for edibility\n",
    "    edibility = soup.find('a', {'href': '/wiki/Edible_mushroom'})\n",
    "    classification[\"edible\"] = 1 if (edibility is not None) else 0\n",
    "\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found : data\n",
      "Failed to get page: 404  for Russula_undulata\n",
      "not found : 7 Russula undulata\n",
      "Failed to get page: 404  for Lycoperdon_excipuliforme\n",
      "not found : 9 Lycoperdon excipuliforme\n",
      "Failed to get page: 404  for Agaricus_crocodilinus\n",
      "not found : 22 Agaricus crocodilinus\n",
      "Failed to get page: 404  for Lycoperdon_utriforme\n",
      "not found : 25 Lycoperdon utriforme\n",
      "Failed to get page: 404  for Russula_parazurea\n",
      "not found : 27 Russula parazurea\n",
      "Failed to get page: 404  for Cuphophyllus_flavipes\n",
      "not found : 41 Cuphophyllus flavipes\n",
      "Failed to get page: 404  for Agaricus_bohusii\n",
      "not found : 42 Agaricus bohusii\n",
      "Failed to get page: 404  for Jackrogersella_multiformis\n",
      "not found : 58 Jackrogersella multiformis\n",
      "Failed to get page: 404  for Amanita_sect._Vaginatae\n",
      "not found : 66 Amanita sect. Vaginatae\n",
      "Failed to get page: 404  for Neoboletus_praestigiator\n",
      "not found : 83 Neoboletus praestigiator\n",
      "Failed to get page: 404  for Amanita_citrina_var._alba\n",
      "not found : 100 Amanita citrina var. alba\n",
      "Failed to get page: 404  for Amanita_citrina_var._citrina\n",
      "not found : 128 Amanita citrina var. citrina\n",
      "Failed to get page: 404  for Cuphophyllus_russocoriaceus\n",
      "not found : 130 Cuphophyllus russocoriaceus\n",
      "Failed to get page: 404  for Coprinellus_silvaticus\n",
      "not found : 139 Coprinellus silvaticus\n",
      "Failed to get page: 404  for Aspropaxillus_giganteus\n",
      "not found : 141 Aspropaxillus giganteus\n",
      "Failed to get page: 404  for Inocybe_lilacina\n",
      "not found : 157 Inocybe lilacina\n",
      "Failed to get page: 404  for Buglossoporus_quercinus\n",
      "not found : 175 Buglossoporus quercinus\n",
      "Failed to get page: 404  for Mucidula_mucida\n",
      "not found : 190 Mucidula mucida\n",
      "Failed to get page: 404  for Heboloma_crustuliniforme\n",
      "not found : 202 Heboloma crustuliniforme\n",
      "Failed to get page: 404  for Scleroderma_spp.\n",
      "not found : 206 Scleroderma spp.\n",
      "Failed to get page: 404  for Leucocybe_connata\n",
      "not found : 209 Leucocybe connata\n",
      "species match: 57 wiki match: 138 not found: 21 total species: 216\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# checking genus if species is not found in the main dataframeb\n",
    "not_found_cnt = 0\n",
    "species_cnt = 0\n",
    "classification_list = []\n",
    "wiki_match_cnt = 0\n",
    "species_match = 0\n",
    "\n",
    "for dir_name, subdir_list, file_list in os.walk(os.path.join(dataset_path, 'data', 'data')):\n",
    "    species_cnt = species_cnt + 1  \n",
    "\n",
    "    # getting common name from subdirectory name       \n",
    "    common_name = dir_name.split(os.sep)[-1].replace('_', ' ')\n",
    "    scientific_name = find_scientific_name(common_name, reference_table,name_exceptions)\n",
    "\n",
    "    # getting information related to the species\n",
    "    try:\n",
    "        scientific_classification = df_classes[df_classes[\"species\"].str.lower() == scientific_name.lower()].iloc[0]\n",
    "        species_match = species_match + 1\n",
    "        # no common name is stored at the moment, which is required to build the test dataset\n",
    "        classification = scientific_classification.to_dict()\n",
    "        classification['common_name'] = common_name\n",
    "        classification_list.append(classification)       \n",
    "    except:\n",
    "        try:\n",
    "            # in this case the  classification from wikipedia is used\n",
    "            classification = scrape_wikipedia_page(scientific_name)\n",
    "            \n",
    "            # species is added only if edible\n",
    "            if classification['edible'] == 1:\n",
    "                classification['common_name'] = common_name\n",
    "                classification_list.append(classification)\n",
    "\n",
    "            wiki_match_cnt = wiki_match_cnt + 1\n",
    "        except:\n",
    "            print(\"not found : \" + str(species_cnt) + \" \" + scientific_name)\n",
    "            not_found_cnt = not_found_cnt + 1\n",
    "\n",
    "print(\"species match: \" + str(species_match) + \" wiki match: \" + str(wiki_match_cnt) + \" not found: \" + str(not_found_cnt) +  \" total species: \" + str(species_cnt))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>common_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Hymenopellis radicata</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Physalacriaceae</td>\n",
       "      <td>Hymenopellis</td>\n",
       "      <td>rooting shank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Agaricus subrufescens</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Agaricaceae</td>\n",
       "      <td>Agaricus</td>\n",
       "      <td>almond mushroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Porpolomopsis calyptriformis</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Hygrophoraceae</td>\n",
       "      <td>Porpolomopsis</td>\n",
       "      <td>pink waxcap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Mycena galericulata</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Mycenaceae</td>\n",
       "      <td>Mycena</td>\n",
       "      <td>common bonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Hygrocybe coccinea</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Hygrophoraceae</td>\n",
       "      <td>Hygrocybe</td>\n",
       "      <td>scarlet waxcap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Amanita phalloides</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Amanitaceae</td>\n",
       "      <td>Amanita</td>\n",
       "      <td>deathcap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Fomes fomentarius</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Polyporales</td>\n",
       "      <td>Polyporaceae</td>\n",
       "      <td>Fomes</td>\n",
       "      <td>hoof fungus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Pseudohydnum gelatinosum</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Auriculariales</td>\n",
       "      <td>incertae sedis</td>\n",
       "      <td>Pseudohydnum</td>\n",
       "      <td>jelly tooth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Agaricus sylvicola</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Agaricaceae</td>\n",
       "      <td>Agaricus</td>\n",
       "      <td>wood mushroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Gliophorus laetus</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Hygrophoraceae</td>\n",
       "      <td>Gliophorus</td>\n",
       "      <td>heath waxcap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          species         phylum           class  \\\n",
       "109         Hymenopellis radicata  Basidiomycota  Agaricomycetes   \n",
       "110         Agaricus subrufescens  Basidiomycota  Agaricomycetes   \n",
       "111  Porpolomopsis calyptriformis  Basidiomycota  Agaricomycetes   \n",
       "113           Mycena galericulata  Basidiomycota  Agaricomycetes   \n",
       "114            Hygrocybe coccinea  Basidiomycota  Agaricomycetes   \n",
       "116            Amanita phalloides  Basidiomycota  Agaricomycetes   \n",
       "118             Fomes fomentarius  Basidiomycota  Agaricomycetes   \n",
       "120      Pseudohydnum gelatinosum  Basidiomycota  Agaricomycetes   \n",
       "121            Agaricus sylvicola  Basidiomycota  Agaricomycetes   \n",
       "123             Gliophorus laetus  Basidiomycota  Agaricomycetes   \n",
       "\n",
       "              order           family          genus      common_name  \n",
       "109      Agaricales  Physalacriaceae   Hymenopellis    rooting shank  \n",
       "110      Agaricales      Agaricaceae       Agaricus  almond mushroom  \n",
       "111      Agaricales   Hygrophoraceae  Porpolomopsis      pink waxcap  \n",
       "113      Agaricales       Mycenaceae         Mycena    common bonnet  \n",
       "114      Agaricales   Hygrophoraceae      Hygrocybe   scarlet waxcap  \n",
       "116      Agaricales      Amanitaceae        Amanita         deathcap  \n",
       "118     Polyporales     Polyporaceae          Fomes      hoof fungus  \n",
       "120  Auriculariales   incertae sedis   Pseudohydnum      jelly tooth  \n",
       "121      Agaricales      Agaricaceae       Agaricus    wood mushroom  \n",
       "123      Agaricales   Hygrophoraceae     Gliophorus     heath waxcap  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Those which don't have a matching wikipedia page are completely removed\n",
    "filtered_list = [d for d in classification_list if (d is not None) ]\n",
    "\n",
    "# now we can update the classification dataframe we the newly identified species. \n",
    "df_classes_update = pd.DataFrame(filtered_list)\n",
    "df_classes_update = df_classes_update.dropna(axis=0)\n",
    "df_classes_update = df_classes_update.drop(columns=['edible'])\n",
    "df_classes_update.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>common_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Hymenopellis radicata</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Physalacriaceae</td>\n",
       "      <td>Hymenopellis</td>\n",
       "      <td>rooting shank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Agaricus subrufescens</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Agaricaceae</td>\n",
       "      <td>Agaricus</td>\n",
       "      <td>almond mushroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Porpolomopsis calyptriformis</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Hygrophoraceae</td>\n",
       "      <td>Porpolomopsis</td>\n",
       "      <td>pink waxcap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Mycena galericulata</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Mycenaceae</td>\n",
       "      <td>Mycena</td>\n",
       "      <td>common bonnet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Hygrocybe coccinea</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Hygrophoraceae</td>\n",
       "      <td>Hygrocybe</td>\n",
       "      <td>scarlet waxcap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Amanita phalloides</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Amanitaceae</td>\n",
       "      <td>Amanita</td>\n",
       "      <td>deathcap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Fomes fomentarius</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Polyporales</td>\n",
       "      <td>Polyporaceae</td>\n",
       "      <td>Fomes</td>\n",
       "      <td>hoof fungus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Pseudohydnum gelatinosum</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Auriculariales</td>\n",
       "      <td>incertae sedis</td>\n",
       "      <td>Pseudohydnum</td>\n",
       "      <td>jelly tooth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Agaricus sylvicola</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Agaricaceae</td>\n",
       "      <td>Agaricus</td>\n",
       "      <td>wood mushroom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Gliophorus laetus</td>\n",
       "      <td>Basidiomycota</td>\n",
       "      <td>Agaricomycetes</td>\n",
       "      <td>Agaricales</td>\n",
       "      <td>Hygrophoraceae</td>\n",
       "      <td>Gliophorus</td>\n",
       "      <td>heath waxcap</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          species         phylum           class  \\\n",
       "184         Hymenopellis radicata  Basidiomycota  Agaricomycetes   \n",
       "185         Agaricus subrufescens  Basidiomycota  Agaricomycetes   \n",
       "186  Porpolomopsis calyptriformis  Basidiomycota  Agaricomycetes   \n",
       "187           Mycena galericulata  Basidiomycota  Agaricomycetes   \n",
       "188            Hygrocybe coccinea  Basidiomycota  Agaricomycetes   \n",
       "189            Amanita phalloides  Basidiomycota  Agaricomycetes   \n",
       "190             Fomes fomentarius  Basidiomycota  Agaricomycetes   \n",
       "191      Pseudohydnum gelatinosum  Basidiomycota  Agaricomycetes   \n",
       "192            Agaricus sylvicola  Basidiomycota  Agaricomycetes   \n",
       "193             Gliophorus laetus  Basidiomycota  Agaricomycetes   \n",
       "\n",
       "              order           family          genus      common_name  \n",
       "184      Agaricales  Physalacriaceae   Hymenopellis    rooting shank  \n",
       "185      Agaricales      Agaricaceae       Agaricus  almond mushroom  \n",
       "186      Agaricales   Hygrophoraceae  Porpolomopsis      pink waxcap  \n",
       "187      Agaricales       Mycenaceae         Mycena    common bonnet  \n",
       "188      Agaricales   Hygrophoraceae      Hygrocybe   scarlet waxcap  \n",
       "189      Agaricales      Amanitaceae        Amanita         deathcap  \n",
       "190     Polyporales     Polyporaceae          Fomes      hoof fungus  \n",
       "191  Auriculariales   incertae sedis   Pseudohydnum      jelly tooth  \n",
       "192      Agaricales      Agaricaceae       Agaricus    wood mushroom  \n",
       "193      Agaricales   Hygrophoraceae     Gliophorus     heath waxcap  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_augmented = pd.concat([df_classes, df_classes_update],ignore_index=True)\n",
    "df_class_augmented.tail(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the order test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# renaming and converting to jpg all images with a unique identifier in their source directory\n",
    "cnt_img = 0\n",
    "start_index = 1000000\n",
    "\n",
    "for dir_name, subdir_list, file_list in os.walk(os.path.join(dataset_path, 'data', 'data')):\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith(\".png\"):\n",
    "            # create unique identifier\n",
    "            unique_identifier  = str(start_index + cnt_img)\n",
    "            cnt_img = cnt_img + 1\n",
    "\n",
    "            # Get the full path of the file\n",
    "            old_file_path = os.path.join(dir_name, file_name)\n",
    "\n",
    "            # Construct the new file name with the unique identifier\n",
    "            new_file_name = unique_identifier + '.jpg'\n",
    "\n",
    "            # Construct the new full path with the new file name\n",
    "            new_file_path = os.path.join(dir_name, new_file_name)\n",
    "\n",
    "            # Open and convert the PNG image to JPG using Pillow\n",
    "            image = Image.open(old_file_path)\n",
    "            image = image.convert(\"RGB\")\n",
    "            image.save(new_file_path, \"JPEG\")\n",
    "\n",
    "            # Remove the old PNG file\n",
    "            os.remove(old_file_path)\n",
    "\n",
    "            print(f\"Converted '{old_file_path}' to '{new_file_path}'\")    \n",
    "            \n",
    "\n",
    "print(cnt_img)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datatset_path = '../../dataset/order_classification/validation'\n",
    "\n",
    "# Create the folder silently\n",
    "os.makedirs(validation_datatset_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_folder(src, dst):\n",
    "    if not os.path.exists(dst):\n",
    "        # If the destination directory doesn't exist, copy entire source directory\n",
    "        shutil.copytree(src, dst)\n",
    "    else:\n",
    "        # If the destination directory exists, copy each file in the source directory\n",
    "        for item in os.listdir(src):\n",
    "            s = os.path.join(src, item)\n",
    "            d = os.path.join(dst, item)\n",
    "            if os.path.isdir(s):\n",
    "                copy_folder(s, d)  # Call function recursively if item is a directory\n",
    "            else:\n",
    "                shutil.copy2(s, d)  # Copy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not found : scarlet elfcup\n",
      "not found : turkey tail\n",
      "not found : purple brittlegill\n",
      "not found : brown birch bolete\n",
      "not found : pestle puffball\n",
      "not found : poplar bell\n",
      "not found : cauliflower fungus\n",
      "not found : hen of the woods\n",
      "not found : stinking dapperling\n",
      "not found : deadly fibrecap\n",
      "not found : golden bootleg\n",
      "not found : horn of plenty\n",
      "not found : common morel\n",
      "not found : common rustgill\n",
      "not found : blushing bracket\n",
      "not found : macro mushroom\n",
      "not found : yellow false truffle\n",
      "not found : mosaic puffball\n",
      "not found : pine bolete\n",
      "not found : powdery brittlegill\n",
      "not found : stinkhorn\n",
      "not found : amethyst chanterelle\n",
      "not found : the blusher\n",
      "not found : birch polypore\n",
      "not found : splitgill\n",
      "not found : thimble morel\n",
      "not found : devils bolete\n",
      "not found : slimy waxcap\n",
      "not found : pavement mushroom\n",
      "not found : yellow foot waxcap\n",
      "not found : medusa mushroom\n",
      "not found : horse mushroom\n",
      "not found : cinnamon bracket\n",
      "not found : trooping funnel\n",
      "not found : freckled dapperling\n",
      "not found : blackening brittlegill\n",
      "not found : woolly milkcap\n",
      "not found : fools funnel\n",
      "not found : grey knight\n",
      "not found : oyster mushroom\n",
      "not found : white dapperling\n",
      "not found : elfin saddle\n",
      "not found : penny bun\n",
      "not found : birch woodwart\n",
      "not found : orange peel fungus\n",
      "not found : grey spotted amanita\n",
      "not found : chicken of the woods\n",
      "not found : beefsteak fungus\n",
      "not found : grisettes\n",
      "not found : terracotta hedgehog\n",
      "not found : meadow waxcap\n",
      "not found : greencracked brittlegill\n",
      "not found : lurid bolete\n",
      "not found : silverleaf fungus\n",
      "not found : the deceiver\n",
      "not found : the miller\n",
      "not found : fly agaric\n",
      "not found : yellow stagshorn\n",
      "not found : saffron milkcap\n",
      "not found : wrinkled peach\n",
      "not found : aniseed funnel\n",
      "not found : scarletina bolete\n",
      "not found : snowy waxcap\n",
      "not found : charcoal burner\n",
      "not found : scaly wood mushroom\n",
      "not found : false chanterelle\n",
      "not found : cucumber cap\n",
      "not found : fleecy milkcap\n",
      "not found : morel\n",
      "not found : beechwood sickener\n",
      "not found : blushing rosette\n",
      "not found : blackening waxcap\n",
      "not found : white false death cap\n",
      "not found : leccinum albostipitatum\n",
      "not found : rosy bonnet\n",
      "not found : ascot hat\n",
      "not found : rooting bolete\n",
      "not found : bay bolete\n",
      "not found : fenugreek milkcap\n",
      "not found : chanterelle\n",
      "not found : field mushroom\n",
      "not found : tawny grisette\n",
      "not found : egghead mottlegill\n",
      "not found : shaggy bracket\n",
      "not found : crimson waxcap\n",
      "not found : bronze bolete\n",
      "not found : field blewit\n",
      "not found : slippery jack\n",
      "not found : vermillion waxcap\n",
      "not found : wood blewit\n",
      "not found : false deathcap\n",
      "not found : velvet shank\n",
      "not found : cedarwood waxcap\n",
      "not found : shaggy inkcap\n",
      "not found : jelly ears\n",
      "not found : orange birch bolete\n",
      "not found : woodland inkcap\n",
      "not found : liberty cap\n",
      "not found : giant funnel\n",
      "not found : tuberous polypore\n",
      "not found : panthercap\n",
      "not found : splendid waxcap\n",
      "not found : hairy curtain crust\n",
      "not found : inky mushroom\n",
      "not found : parasol\n",
      "not found : scarlet caterpillarclub\n",
      "not found : spectacular rustgill\n",
      "not found : deadly webcap\n",
      "not found : jubilee waxcap\n",
      "not found : lilac fibrecap\n",
      "not found : destroying angel\n",
      "not found : amethyst deceiver\n",
      "not found : hedgehog fungus\n",
      "not found : white fibrecap\n",
      "not found : root rot\n",
      "not found : winter chanterelle\n",
      "not found : dyers mazegill\n",
      "not found : st georges mushroom\n",
      "not found : sheathed woodtuft\n",
      "not found : oak mazegill\n",
      "not found : blushing wood mushroom\n",
      "not found : oak polypore\n",
      "not found : pale oyster\n",
      "not found : orange bolete\n",
      "not found : data - Raccourci.lnk\n",
      "not found : magpie inkcap\n",
      "not found : yellow stainer\n",
      "not found : spring fieldcap\n",
      "not found : warted amanita\n",
      "not found : golden waxcap\n",
      "not found : crimped gill\n",
      "not found : porcelain fungus\n",
      "not found : smoky bracket\n",
      "not found : the goblet\n",
      "not found : king alfreds cakes\n",
      "not found : black bulgar\n",
      "not found : stubble rosegill\n",
      "not found : giant puffball\n",
      "not found : red belted bracket\n",
      "not found : poison pie\n",
      "not found : sulphur tuft\n",
      "not found : slender parasol\n",
      "not found : earthballs\n",
      "not found : fairy ring champignons\n",
      "not found : white domecap\n",
      "not found : geranium brittlegill\n",
      "not found : oak bolete\n",
      "not found : clustered domecap\n",
      "not found : amanita gemmata\n",
      "found: 67 / 67\n"
     ]
    }
   ],
   "source": [
    "# from the subdirectory name, common name is extracted and matched to its order\n",
    "not_found_cnt = 0\n",
    "rootdir = os.path.join(dataset_path, 'data', 'data')\n",
    "\n",
    "# Get a list of all subdirectories\n",
    "subdirectories = [d for d in os.listdir(rootdir)]\n",
    "\n",
    "# Create a dictionary to store the mapping of subdirectories to orders\n",
    "subdir_to_order = {}\n",
    "\n",
    "# Iterate through subdirectories and match with 'common_name' or 'species'\n",
    "for subdir in subdirectories:\n",
    "    common_name = subdir.replace('_', ' ')\n",
    "\n",
    "    scientific_name = find_scientific_name(common_name, df_classes_update.rename(columns={'species': 'scientific_name'}),name_exceptions)\n",
    "\n",
    "    matching_species = df_classes_update[df_classes_update['species'] == scientific_name]\n",
    "\n",
    "    if not matching_species.empty:\n",
    "        order_value = matching_species.iloc[0]['order'].lower()\n",
    "        subdir_to_order[subdir] = order_value\n",
    "\n",
    "        # Copy the source folder and its contents to the destination folder\n",
    "        copy_folder(os.path.join(rootdir, subdir), os.path.join(validation_datatset_path, order_value))\n",
    "        #shutil.copytree(os.path.join(rootdir, subdir), os.path.join(validation_datatset_path, order_value))\n",
    "    else: \n",
    "        # at that stage not found means not edible\n",
    "        not_found_cnt = not_found_cnt + 1\n",
    "\n",
    "print(\"found: \" + str(len(subdirectories) - not_found_cnt) + \" / \" + str(df_classes_update['species'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
